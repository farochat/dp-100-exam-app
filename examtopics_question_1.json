[
    {
        "question_id": "examtopics_cc5631239d9d4f8c811db0090aaad575",
        "type": "multiple_choice_single_answer",
        "question": "This question is included in a number of questions that depicts the identical set-up. However, every question has a distinctive result. Establish if the recommendation satisfies the requirements.\n\nYou have been tasked with employing a machine learning model, which makes use of a PostgreSQL database and needs GPU processing, to forecast prices.\n\nYou are preparing to create a virtual machine that has the necessary tools built into it.\n\nYou need to make use of the correct virtual machine type.\n\nRecommendation: You make use of a Geo AI Data Science Virtual Machine (Geo-DSVM) Windows edition.\n\nWill the requirements be satisfied?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_c4af0d4690424675b4598cfc160e37d8",
        "type": "multiple_choice_single_answer",
        "question": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\n\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nYou use Azure Machine Learning designer to load the following datasets into an experiment:\n\nDataset1 | Age | Length | Width |\n|----------|----------|----------|\n| 3       | 22       | 13       |\n| 7       | 11       | 86       |\n| 18       | 32       | 95       | \n\n\nDataset2 \n\n\nYou need to create a dataset that has the same columns and header row as the input datasets and contains all rows from both input datasets.\n\nSolution: Use the Join Data module.\n\nDoes the solution meet the goal?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: B.\nCommunity:\n100% for A\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_d371129d2b03414a859330b38eec34f0",
        "type": "multiple_choice_single_answer",
        "question": "You write a Python script that processes data in a comma-separated values (CSV) file.\n\nYou plan to run this script as an Azure Machine Learning experiment.\n\nThe script loads the data and determines the number of rows it contains using the following code:\n\n```\nfrom azureml.core import\nimport pandas as pd\n\nrun = Run.get_context()\ndata = pd.read_csv(\"./data.csv\")\nrows = len(data)\n# record row_count metric here\n```\n\nYou need to record the row count as a metric named row_count that can be returned using the get_metrics method of the Run object after the experiment run completes.\n\nWhich code should you use?",
        "options": [
            {
                "id": "A",
                "text": "run.upload_file(T3 row_count', './data.csv')",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "run.log('row_count', rows)",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "run.tag('row_count', rows)",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "run.log_table('row_count', rows)",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "E",
                "text": "run.log_row('row_count', rows)",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_2ed8357f672e42c895e9e26274b25ed8",
        "type": "multiple_choice_multiple_answer",
        "question": "You run a script as an experiment in Azure Machine Learning.\n\nYou have a Run object named run that references the experiment run. You must review the log files that were generated during the experiment run.\n\nYou need to download the log files to a local folder for review.\n\nWhich two code segments can you run to achieve this goal? Each correct answer presents a complete solution.\n\nNOTE: Each correct selection is worth one point.",
        "options": [
            {
                "id": "A",
                "text": "run.get_details()",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "run.get_file_names()",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "run.get_metrics()",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "run.download_files(output_directory='./runfiles')",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "E",
                "text": "run.get_all_logs(destination='./runlogs')",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: AE.\nCommunity:\n100% for DE\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_78b27c3255e14f49bab0a03773c91c34",
        "type": "multiple_choice_multiple_answer",
        "question": "You create an Azure Machine Learning managed compute resource. The compute resource is configured as follows:\n\n- Minimum nodes: 2\n\n- Maximum nodes: 4\n\nYou must decrease the minimum number of nodes and increase the maximum number of nodes to the following values:\n\n- Minimum nodes: 0\n\n- Maximum nodes: 8\n\nYou need to reconfigure the compute resource.\n\nWhich three methods can you use? Each correct answer presents a complete solution.\n\nNOTE: Each correct selection is worth one point.",
        "options": [
            {
                "id": "A",
                "text": "Azure Machine Learning designer",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "MLClient class in Python SDK v2",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Azure Machine Learning studio",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Azure CLI ml extension v2",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "E",
                "text": "BuildContext class in Python SDK v2",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: ACD.\nCommunity:\n83% for BCD\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_e83d491092bc4e8a82072e0c316422d6",
        "type": "multiple_choice_single_answer",
        "question": "This question is included in a number of questions that depicts the identical set-up. However, every question has a distinctive result. Establish if the recommendation satisfies the requirements.\n\nYou have been tasked with employing a machine learning model, which makes use of a PostgreSQL database and needs GPU processing, to forecast prices.\n\nYou are preparing to create a virtual machine that has the necessary tools built into it.\n\nYou need to make use of the correct virtual machine type.\n\nRecommendation: You make use of a Data Science Virtual Machine (DSVM) Windows edition.\n\nWill the requirements be satisfied?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: A.\nCommunity:\n58% for B\n42% for A\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_92bb1fdb9dcc441fb9356a171e3d5a84",
        "type": "multiple_choice_single_answer",
        "question": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\n\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nYou train a classification model by using a logistic regression algorithm.\n\nYou must be able to explain the model's predictions by calculating the importance of each feature, both as an overall global relative importance value and as a measure of local importance for a specific set of predictions.\n\nYou need to create an explainer that you can use to retrieve the required global and local feature importance values.\n\nSolution: Create a TabularExplainer.\n\nDoes the solution meet the goal?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: B.\nCommunity:\n100% for A\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_7b9ac2f95c014eb589b7c135fc09c3e9",
        "type": "multiple_choice_multiple_answer",
        "question": "You are attaching an Azure Databricks-based compute resource to an Azure Machine Learning development workspace.\n\nYou need to configure parameters to attach the resource.\n\nWhich three parameters should you use? Each correct answer presents part of the solution.\n\nNOTE: Each correct selection is worth one point.",
        "options": [
            {
                "id": "A",
                "text": "Workspace name",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Compute name",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Workspace user credentials",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Workspace resource ID",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "E",
                "text": "Access token",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_856d82080de549a3b6a8480cc94a2379",
        "type": "multiple_choice_single_answer",
        "question": "This question is included in a number of questions that depicts the identical set-up. However, every question has a distinctive result. Establish if the recommendation satisfies the requirements.\n\nYou are in the process of creating a machine learning model. Your dataset includes rows with null and missing values.\n\nYou plan to make use of the Clean Missing Data module in Azure Machine Learning Studio to detect and fix the null and missing values in the dataset.\n\nRecommendation: You make use of the Custom substitution value option.\n\nWill the requirements be satisfied?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: B.\nCommunity:\n76% for A\n24% for B\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_0d538796535e4792a13ed02527f8e507",
        "type": "multiple_choice_multiple_answer",
        "question": "You create an Azure Machine Learning workspace. You are preparing a local Python environment on a laptop computer. You want to use the laptop to connect to the workspace and run experiments.\n\nYou create the following config.json file.\n\n{\n\n\"workspace_name\" : \"ml-workspace\"\n\n}\n\nYou must use the Azure Machine Learning SDK to interact with data and experiments in the workspace.\n\nYou need to configure the config.json file to connect to the workspace from the Python environment.\n\nWhich two additional parameters must you add to the config.json file in order to connect to the workspace? Each correct answer presents part of the solution.\n\nNOTE: Each correct selection is worth one point.",
        "options": [
            {
                "id": "A",
                "text": "login",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "resource_group",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "subscription_id",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "key",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "E",
                "text": "region",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_4176487ce8784d60b3b7deaaabb3733a",
        "type": "multiple_choice_single_answer",
        "question": "You use the following code to run a script as an experiment in Azure Machine Learning:\n\nfrom azureml.core import Workspace, Experiment, Run\n\nfrom azureml.core import RunConfig, ScriptRunConfig\n\nws = Workspace. from_config()\n\nrun_config = RunConfiguration()\n\nrun_config.target='local'\n\nscript_config = ScriptRunConfig(source_directory='./script', script='experiment.py', run_config=run_config)\nexperiment = Experiment(workspace=ws, name='script experiment\u2019)\n\nrun = experiment.submit(config=script_config)\n\nrun.wait_for_completion()\n\n\nYou must identify the output files that are generated by the experiment run.\n\nYou need to add code to retrieve the output file names.\n\nWhich code segment should you add to the script?",
        "options": [
            {
                "id": "A",
                "text": "files = run.get_properties()",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "files= run.get_file_names()",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "files = run.get_details_with_logs()",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "files = run.get_metrics()",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "E",
                "text": "files = run.get_details()",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_2326c004abba4406b839ea568cd1668b",
        "type": "multiple_choice_single_answer",
        "question": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\n\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nYou have the following Azure subscriptions and Azure Machine Learning service workspaces:\n\nSubscription Workspace Comment\n385bdfe5-4cef-4ad4-b977- ml-default | This is default subscription.\n386d92727c9\n5a5891d1-557a-4234-9b83- ml-project | The information required to uniquely identify this\n2e90412b1068 workspace is stored in the file config json in the same folder as the Python script.\n\n\n\nYou need to obtain a reference to the ml-project workspace.\n\nSolution: Run the following Python code:\n\nDoes the solution meet the goal?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_95d37dc5524c473c8fedf9e082ae6472",
        "type": "multiple_choice_single_answer",
        "question": "You plan to run a script as an experiment using a Script Run Configuration. The script uses modules from the scipy library as well as several\n\nPython packages that are not typically installed in a default conda environment.\n\nYou plan to run the experiment on your local workstation for small datasets and scale out the experiment by running it on more powerful remote compute clusters for larger datasets.\n\nYou need to ensure that the experiment runs successfully on local and remote compute with the least administrative effort.\n\nWhat should you do?",
        "options": [
            {
                "id": "A",
                "text": "Do not specify an environment in the run configuration for the experiment. Run the experiment by using the default environment.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Create a virtual machine (VM) with the required Python configuration and attach the VM as a compute target. Use this compute target for all experiment runs.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Create and register an Environment that includes the required packages. Use this Environment for all experiment runs.",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Create a config.yaml file defining the conda packages that are required and save the file in the experiment folder.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "E",
                "text": "Always run the experiment with an Estimator by using the default packages.",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_d1061a1b1e4a4ae59a81f2307e344727",
        "type": "multiple_choice_single_answer",
        "question": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\n\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nYou have the following Azure subscriptions and Azure Machine Learning service workspaces:\n\nSubscription Workspace Comment\n385bdfe5-4cef-4ad4-b977- ml-default | This is default subscription.\n386d92727c9\n5a5891d1-557a-4234-9b83- ml-project | The information required to uniquely identify this\n2e90412b1068 workspace is stored in the file config json in the same folder as the Python script.\n\n\n\nYou need to obtain a reference to the ml-project workspace.\n\nSolution: Run the following Python code:\n\nDoes the solution meet the goal?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: A.\nCommunity:\n83% for B\n17% for A(17%)\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_d0181195f12f4a69acd33352c81db2e3",
        "type": "multiple_choice_single_answer",
        "question": "You use Azure Machine Learning designer to create a training pipeline for a regression model.\n\nYou need to prepare the pipeline for deployment as an endpoint that generates predictions asynchronously for a dataset of input data values.\n\nWhat should you do?",
        "options": [
            {
                "id": "A",
                "text": "Clone the training pipeline.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Create a batch inference pipeline from the training pipeline.",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Create a real-time inference pipeline from the training pipeline.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Replace the dataset in the training pipeline with an Enter Data Manually module.",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: C.\nCommunity:\n100% for B\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_94bb9a20ce1f4f2dba5ab9af9e109252",
        "type": "multiple_choice_single_answer",
        "question": "You use an Azure Machine Learning workspace.\n\nYou have a trained model that must be deployed as a web service. Users must authenticate by using Azure Active Directory.\n\nWhat should you do?",
        "options": [
            {
                "id": "A",
                "text": "Deploy the model to Azure Kubernetes Service (AKS). During deployment, set the token_auth_enabled parameter of the target configuration object to true",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Deploy the model to Azure Container Instances. During deployment, set the auth_enabled parameter of the target configuration object to true",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Deploy the model to Azure Container Instances. During deployment, set the token_auth_enabled parameter of the target configuration object to true",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Deploy the model to Azure Kubernetes Service (AKS). During deployment, set the auth.enabled parameter of the target configuration object to true",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_ce73b3a8e3c04c00a6197a89ecf16beb",
        "type": "multiple_choice_single_answer",
        "question": "You create a workspace to include a compute instance by using Azure Machine Learning Studio. You are developing a Python SDK v2 notebook in the workspace.\n\nYou need to use Intellisense in the notebook.\n\nWhat should you do?",
        "options": [
            {
                "id": "A",
                "text": "Stop the compute instance.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Start the compute instance.",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Run a %pip magic function on the compute instance.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Run a !pip magic function on the compute instance.",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: C.\nCommunity:\n100% for B\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_c018e723c7af42508cc746f7711ccebe",
        "type": "multiple_choice_single_answer",
        "question": "You train a machine learning model.\n\nYou must deploy the model as a real-time inference service for testing. The service requires low CPU utilization and less than 48 MB of RAM. The compute target for the deployed service must initialize automatically while minimizing cost and administrative overhead.\n\nWhich compute target should you use?",
        "options": [
            {
                "id": "A",
                "text": "Azure Container Instance (ACI)",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "attached Azure Databricks cluster",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Azure Kubernetes Service (AKS) inference cluster",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Azure Machine Learning compute cluster",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_513db85da45e4d9caadd2f67418fe20e",
        "type": "multiple_choice_single_answer",
        "question": "You are building a machine learning model for translating English language textual content into French language textual content.\n\nYou need to build and train the machine learning model to learn the sequence of the textual content.\n\nWhich type of neural network should you use?",
        "options": [
            {
                "id": "A",
                "text": "Multilayer Perceptions (MLPs)",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Convolutional Neural Networks (CNNs)",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Recurrent Neural Networks (RNNs)",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Generative Adversarial Networks (GANs)",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: C.\nCommunity:\n100% for (100%)\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_4eb919312e3f4e77b4b6e4300db69985",
        "type": "multiple_choice_single_answer",
        "question": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\n\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nYou have the following Azure subscriptions and Azure Machine Learning service workspaces:\n\nSubscription Workspace Comment\n385bdfe5-4cef-4ad4-b977- ml-default | This is default subscription.\n386d92727c9\n5a5891d1-557a-4234-9b83- ml-project | The information required to uniquely identify this\n2e90412b1068 workspace is stored in the file config json in the same folder as the Python script.\n\n\n\nYou need to obtain a reference to the ml-project workspace.\n\nSolution: Run the following Python code:\n\nDoes the solution meet the goal?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_94852dd86ab9432bb049833695965bfa",
        "type": "multiple_choice_single_answer",
        "question": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\n\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nYou use Azure Machine Learning designer to load the following datasets into an experiment:\n\nDataset1 \n\n\nDataset2 \n\n\nYou need to create a dataset that has the same columns and header row as the input datasets and contains all rows from both input datasets.\n\nSolution: Use the Execute Python Script module.\n\nDoes the solution meet the goal?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: B.\nCommunity:\n92% for A\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_6f1143afa2fe4fd28cdf25caca93e1e0",
        "type": "multiple_choice_single_answer",
        "question": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\n\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nYou plan to use a Python script to run an Azure Machine Learning experiment. The script creates a reference to the experiment run context, loads data from a file, identifies the set of unique values for the label column, and completes the experiment run:\n\nfrom azureml.core import Run\nmport pandas as pd\n\nrun = Run.get_context()\n\ndata = pd.read_csv('data.csv')\nlabel_vals = data['label'].unique()\n# Add code to record metrics here\nrun.complete()\n\n\nThe experiment must record the unique labels in the data as metrics for the run that can be reviewed later.\n\nYou must add code to the script to record the unique label values as run metrics at the point indicated by the comment.\n\nSolution: Replace the comment with the following code:\n\nfor label_val in label_vals:\n\nrun.log('Label Values', label_val)\n\nDoes the solution meet the goal?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: A.\nCommunity:\n64% for B\n36% for A\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_d27c1d67f4ff474e858961cff4c0d7a4",
        "type": "multiple_choice_single_answer",
        "question": "This question is included in a number of questions that depicts the identical set-up. However, every question has a distinctive result. Establish if the recommendation satisfies the requirements.\n\nYou are in the process of carrying out feature engineering on a dataset.\n\nYou want to add a feature to the dataset and fill the column value.\n\nRecommendation: You must make use of the Edit Metadata Azure Machine Learning Studio module.\n\nWill the requirements be satisfied?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: A.\nCommunity:\n89% for B\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_1bc0f981bd244966883b4774a610f903",
        "type": "multiple_choice_single_answer",
        "question": "You use the Azure Machine Learning service to create a tabular dataset named training_data. You plan to use this dataset in a training script.\n\nYou create a variable that references the dataset using the following code: training_ds = workspace.datasets.get(\"training_data\")\n\nYou define an estimator to run the script.\n\nYou need to set the correct property of the estimator to ensure that your script can access the training_data dataset.\n\nWhich property should you set?",
        "options": [
            {
                "id": "A",
                "text": "environment_definition = {\"training_data\":training_ds}",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "inputs = [training_ds.as_named_input('training_ds')]",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "script_params = {\"--training_ds\":training_ds}",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "source_directory = training_ds",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_0b189354cd12461d956738b0b0dbff66",
        "type": "multiple_choice_single_answer",
        "question": "You are determining if two sets of data are significantly different from one another by using Azure Machine Learning Studio.\n\nEstimated values in one set of data may be more than or less than reference values in the other set of data. You must produce a distribution that has a constant Type I error as a function of the correlation.\n\nYou need to produce the distribution.\n\nWhich type of distribution should you produce?",
        "options": [
            {
                "id": "A",
                "text": "Unpaired t-test with a two-tail option",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Unpaired t-test with a one-tail option",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Paired t-test with a one-tail option",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Paired t-test with a two-tail option",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_5f134fa4081742b38d45943f14029ac2",
        "type": "multiple_choice_single_answer",
        "question": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\n\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nYou plan to use a Python script to run an Azure Machine Learning experiment. The script creates a reference to the experiment run context, loads data from a file, identifies the set of unique values for the label column, and completes the experiment run:\n\nfrom azureml.core import Run\nimport pandas as pd\n\nrun = Run.get_context()\n\ndata = pd.read_csv('data.csv')\nlabel_vals = data['label'].unique()\n# Add code to record metrics here\nrun.complete()\n\n\nThe experiment must record the unique labels in the data as metrics for the run that can be reviewed later.\n\nYou must add code to the script to record the unique label values as run metrics at the point indicated by the comment.\n\nSolution: Replace the comment with the following code:\n\nrun.upload_file('outputs/labels.csv', './data.csv')\n\nDoes the solution meet the goal?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_7eaef3486e07491c819dd14f240f2c47",
        "type": "multiple_choice_single_answer",
        "question": "You create and register a model in an Azure Machine Learning workspace.\n\nYou must use the Azure Machine Learning SDK to implement a batch inference pipeline that uses a ParallelRunStep to score input data using the model. You must specify a value for the ParallelRunConfig compute_target setting of the pipeline step.\n\nYou need to create the compute target.\n\nWhich class should you use?",
        "options": [
            {
                "id": "A",
                "text": "BatchCompute",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "AdlaCompute",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "AmlCompute",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "AksCompute",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: C.\nCommunity:\n100% for (100%)\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_fc461bff476a4c6389756628baefd6b8",
        "type": "multiple_choice_single_answer",
        "question": "You create a batch inference pipeline by using the Azure ML SDK. You configure the pipeline parameters by executing the following code:\n\n```\nfrom azureml.contrib.pipeline.steps import ParallelRunConfig\nparallel_run_config = ParallelRunConfig(\n    source_directory=scripts_folder,\n    entry_script=batch_pipeline.py,\n    mini_batch_size=5,\n    error_threshold=10,\n    output_action=append_row,\n    environment=batch_env,\n    compute_target=compute_ target,\n    logging_level=DEBUG,\n    node _count=4\n)\n```\n\nYou need to obtain the output from the pipeline execution.\n\nWhere will you find the output?",
        "options": [
            {
                "id": "A",
                "text": "the digit_identification.py script",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "the debug log",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "the Activity Log in the Azure portal for the Machine Learning workspace",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "the Inference Clusters tab in Machine Learning studio",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "E",
                "text": "a file named parallel_run_step.txt located in the output folder",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_06480b070f074da1bd446f607541a0ac",
        "type": "multiple_choice_single_answer",
        "question": "You have recently concluded the construction of a binary classification machine learning model.\n\nYou are currently assessing the model. You want to make use of a visualization that allows for precision to be used as the measurement for the assessment.\n\nWhich of the following actions should you take?",
        "options": [
            {
                "id": "A",
                "text": "You should consider using Venn diagram visualization.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "You should consider using Receiver Operating Characteristic (ROC) curve visualization.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "You should consider using Box plot visualization.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "You should consider using the Binary classification confusion matrix visualization.",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_2972914cb71b468db2e883651e73e89c",
        "type": "multiple_choice_single_answer",
        "question": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\n\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nYou create a model to forecast weather conditions based on historical data.\n\nYou need to create a pipeline that runs a processing script to load data from a datastore and pass the processed data to a machine learning model training script.\n\nSolution: Run the following code:\n\ndata_store = Datastore.get(ws, \u201cml-data\u201d)\ndata_input = DataReference(\ndatastore = data_store,\ndata_reference_name = \u2018training_data\u2019,\npath_on_datastore = \u201ctrain/data txt\u201d)\ndata_output = PipelineData(\u201cprocessed_data\u201d, datastore=datastore)\nprocess_step = PythonScriptStep(script_name= \u201cprocess.py\u201d,\narguments=[ \u201c- -data\u201d, data_input], outputs=[data_output],\ncompute_target=aml_compute, source_directory=process_directory)\ntrain_step = PythonScriptStep(script_name= \u201ctrain.py\u2019,\narguments=[\"- -data\u201d, data_output], inputs=[data_output],\ncompute_target=aml_compute, source_directory=train_directory)\npipeline = Pipeline(workspace=ws, steps = [process_step, train_step])\n\n\nDoes the solution meet the goal?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_8f2cb0c1983d4ba2ba5fe20776533fe7",
        "type": "multiple_choice_single_answer",
        "question": "You are creating a new Azure Machine Learning pipeline using the designer.\n\nThe pipeline must train a model using data in a comma-separated values (CSV) file that is published on a website. You have not created a dataset for this file.\n\nYou need to ingest the data from the CSV file into the designer pipeline using the minimal administrative effort.\n\nWhich module should you add to the pipeline in Designer?",
        "options": [
            {
                "id": "A",
                "text": "Convert to CSV",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Enter Data Manually",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Import Data",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Dataset",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: D.\nCommunity:\n100% for C(100%)\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_94aed7f6e77642178a1409ad83dd87dd",
        "type": "multiple_choice_single_answer",
        "question": "You are planning to host practical training to acquaint learners with data visualization creation using Python. Learner devices are able to connect to the internet.\n\nLearner devices are currently NOT configured for Python development. Also, learners are unable to install software on their devices as they lack administrator permissions. Furthermore, they are unable to access Azure subscriptions.\n\nIt is imperative that learners are able to execute Python-based data visualization code.\n\nWhich of the following actions should you take?",
        "options": [
            {
                "id": "A",
                "text": "You should consider configuring the use of Azure Container Instance.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "You should consider configuring the use of Azure BatchAI.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "You should consider configuring the use of Azure Notebooks.",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "You should consider configuring the use of Azure Kubernetes Service.",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_c8c953d757fe42fd8b4e42811f3eaf98",
        "type": "multiple_choice_single_answer",
        "question": "You develop and train a machine learning model to predict fraudulent transactions for a hotel booking website.\n\nTrafic to the site varies considerably. The site experiences heavy trafic on Monday and Friday and much lower trafic on other days. Holidays are also high web trafic days.\n\nYou need to deploy the model as an Azure Machine Learning real-time web service endpoint on compute that can dynamically scale up and down to support demand.\n\nWhich deployment compute option should you use?",
        "options": [
            {
                "id": "A",
                "text": "attached Azure Databricks cluster",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Azure Container Instance (ACI)",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Azure Kubernetes Service (AKS) inference cluster",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Azure Machine Learning Compute Instance",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "E",
                "text": "attached virtual machine in a different region",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: D.\nCommunity:\n100% for C\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_d607d29c2d2e4acb9acf553db9ef81b2",
        "type": "multiple_choice_single_answer",
        "question": "You are creating a binary classification by using a two-class logistic regression model.\n\nYou need to evaluate the model results for imbalance.\n\nWhich evaluation metric should you use?",
        "options": [
            {
                "id": "A",
                "text": "Relative Absolute Error",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "AUC Curve",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Mean Absolute Error",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Relative Squared Error",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "E",
                "text": "Accuracy",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "F",
                "text": "Root Mean Square Error",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_4b2c6df88fb54ea6b7a95ade8410b34b",
        "type": "multiple_choice_multiple_answer",
        "question": "You plan to use the Hyperdrive feature of Azure Machine Learning to determine the optimal hyperparameter values when training a model.\n\nYou must use Hyperdrive to try combinations of the following hyperparameter values. You must not apply an early termination policy.\n\n\u2711 learning_rate: any value between 0.001 and 0.1\n\n\u2711 batch_size: 16, 32, or 64\n\nYou need to configure the sampling method for the Hyperdrive experiment.\n\nWhich two sampling methods can you use? Each correct answer is a complete solution.\n\nNOTE: Each correct selection is worth one point.",
        "options": [
            {
                "id": "A",
                "text": "No sampling",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Grid sampling",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Bayesian sampling",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Random sampling",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_190b45eb6771437baed0c0aca521d1e3",
        "type": "multiple_choice_multiple_answer",
        "question": "You manage an Azure Machine Learning workspace.\n\nYou must log multiple metrics by using MLfiow.\n\nYou need to maximize logging performance.\n\nWhat are two possible ways to achieve this goal? Each correct answer presents a complete solution.\n\nNOTE: Each correct selection is worth one point.",
        "options": [
            {
                "id": "A",
                "text": "MLfiowClient.log_batch",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "mlfiow.log_metrics",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "mlfiow.log_metric",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "mlfiow.log_param",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_f632dd8ad54c4582a1bbb3c616190d4a",
        "type": "multiple_choice_single_answer",
        "question": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\n\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nYou train and register a machine learning model.\n\nYou plan to deploy the model as a real-time web service. Applications must use key-based authentication to use the model.\n\nYou need to deploy the web service.\n\nSolution:\n\nCreate an AciWebservice instance.\n\nSet the value of the auth_enabled property to False.\n\nSet the value of the token_auth_enabled property to True.\n\nDeploy the model to the service.\n\nDoes the solution meet the goal?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_8c3f86f8a62a49ea81d32a5913853f2a",
        "type": "multiple_choice_single_answer",
        "question": "You manage an Azure Machine Learning workspace. The workspace includes an Azure Machine Learning Kubernetes compute target configured as an Azure Kubernetes Service (AKS) cluster named AKS1. AKS1 is configured to enable the targeting of different nodes to train workloads.\n\nYou must run a command job on AKS1 by using the Azure ML Python SDK v2. The command job must select different types of compute nodes.\n\nThe compute node types must be specified by using a command parameter.\n\nYou need to configure the command parameter.\n\nWhich parameter should you use?",
        "options": [
            {
                "id": "A",
                "text": "environment",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "compute",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "limits",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "instance_type",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_affea83e1d994e36b5ce774e20ac8e10",
        "type": "multiple_choice_multiple_answer",
        "question": "You are analyzing a dataset by using Azure Machine Learning Studio.\n\nYou need to generate a statistical summary that contains the p-value and the unique count for each feature column.\n\nWhich two modules can you use? Each correct answer presents a complete solution.\n\nNOTE: Each correct selection is worth one point.",
        "options": [
            {
                "id": "A",
                "text": "Computer Linear Correlation",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Export Count Table",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Execute Python Script",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Convert to Indicator Values",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "E",
                "text": "Summarize Data",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: BE.\nCommunity:\n100% for CE\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_92d25364208f4b2796f43cec72a88f7b",
        "type": "multiple_choice_single_answer",
        "question": "You use Azure Machine Learning designer to create a real-time service endpoint. You have a single Azure Machine Learning service compute resource.\n\nYou train the model and prepare the real-time pipeline for deployment.\n\nYou need to publish the inference pipeline as a web service.\n\nWhich compute type should you use?",
        "options": [
            {
                "id": "A",
                "text": "a new Machine Learning Compute resource",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Azure Kubernetes Services",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "HDInsight",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "the existing Machine Learning Compute resource",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "E",
                "text": "Azure Databricks",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_8e4c0b3845c84c088a50f9638cf7c897",
        "type": "multiple_choice_single_answer",
        "question": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\n\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nAn IT department creates the following Azure resource groups and resources:\n\nan Azure Machine Leaming workspace named amlworkspace\nan Azure Storage account named amlworkspace12345 an Application Insights instance named amlworkspace54321\nan Azure Key Vault named amliworkspace67890 an Azure Container Registry named amlworkspace09876\n\nA virtual machine named mlivm with the following configuration:\n\ngeneral_compute\n\nOperating system: Ubuntu Linux\nSoftware installed: Python 3.6 and Jupyter Notebooks\n\nThe IT department creates an Azure Kubernetes Service (AKS)-based inference compute target named aks-cluster in the Azure Machine Learning workspace.\n\nYou have a Microsoft Surface Book computer with a GPU. Python 3.6 and Visual Studio Code are installed.\n\nYou need to run a script that trains a deep neural network (DNN) model and logs the loss and accuracy metrics.\n\nSolution: Install the Azure ML SDK on the Surface Book. Run Python code to connect to the workspace. Run the training script as an experiment on the aks- cluster compute target.\n\nDoes the solution meet the goal?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_02b1174591a045eda97564805e2207a2",
        "type": "multiple_choice_single_answer",
        "question": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\n\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nYou are creating a new experiment in Azure Machine Learning Studio.\n\nOne class has a much smaller number of observations than the other classes in the training set.\n\nYou need to select an appropriate data sampling strategy to compensate for the class imbalance.\n\nSolution: You use the Stratified split for the sampling mode.\n\nDoes the solution meet the goal?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_372dfaa2e0044ad0b77f8fb46d116a55",
        "type": "multiple_choice_single_answer",
        "question": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\n\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nYou train a classification model by using a logistic regression algorithm.\n\nYou must be able to explain the model's predictions by calculating the importance of each feature, both as an overall global relative importance value and as a measure of local importance for a specific set of predictions.\n\nYou need to create an explainer that you can use to retrieve the required global and local feature importance values.\n\nSolution: Create a PFIExplainer.\n\nDoes the solution meet the goal?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: A.\nCommunity:\n100% for B\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_c3c543631d9b4f709b1417514c9cb5b3",
        "type": "multiple_choice_single_answer",
        "question": "You have been tasked with designing a deep learning model, which accommodates the most recent edition of Python, to recognize language.\n\nYou have to include a suitable deep learning framework in the Data Science Virtual Machine (DSVM).\n\nWhich of the following actions should you take?",
        "options": [
            {
                "id": "A",
                "text": "You should consider including Rattle.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "You should consider including TensorFlow.",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "You should consider including Theano.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "You should consider including Chainer.",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_9bd4968e81d04c6389303a4cce0cd7ec",
        "type": "multiple_choice_single_answer",
        "question": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\n\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nYou train and register a machine learning model.\n\nYou plan to deploy the model as a real-time web service. Applications must use key-based authentication to use the model.\n\nYou need to deploy the web service.\n\nSolution:\n\nCreate an AciWebservice instance.\n\nSet the value of the auth_enabled property to True.\n\nDeploy the model to the service.\n\nDoes the solution meet the goal?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_a3d1015b3f8b495f959a0e45b1d10241",
        "type": "multiple_choice_single_answer",
        "question": "You want to train a classification model using data located in a comma-separated values (CSV) file.\n\nThe classification model will be trained via the Automated Machine Learning interface using the Classification task type.\n\nYou have been informed that only linear models need to be assessed by the Automated Machine Learning.\n\nWhich of the following actions should you take?",
        "options": [
            {
                "id": "A",
                "text": "You should disable deep learning.",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "You should enable automatic featurization.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "You should disable automatic featurization.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "You should set the task type to Forecasting.",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: C.\nCommunity:\n100% for A\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_2f003113d30242bcb9f69385ff071c23",
        "type": "multiple_choice_single_answer",
        "question": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\n\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nYou create a model to forecast weather conditions based on historical data.\n\nYou need to create a pipeline that runs a processing script to load data from a datastore and pass the processed data to a machine learning model training script.\n\nSolution: Run the following code:\n\ndatastore = ws.get_default_datastore()\n\ndata_input = PipelineData(\"raw data\", datastore=rawdatastore)\n\ndata_output = PipelineData(\"processed data\", datastore=datastore)\n\nprocess step = PythonScriptStep(script_name=\"process.py\",\narguments=[\"--data_for_train\", data_input],\noutputs=[data_output], compute_target=aml_compute,\nsource_directory=process directory)\n\ntrain_step = PythonScriptStep(script_name=\"train.py\",\narguments=[\"--data_for_train\", data_input], inputs=[data_output],\ncompute _target=aml_compute, source _directory=train_ directory)\n\npipeline = Pipeline(workspace=ws, steps=[process step, train_step])\n\n\nDoes the solution meet the goal?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_b461ef03fb084c65a57a1765039d37e9",
        "type": "multiple_choice_single_answer",
        "question": "You make use of Azure Machine Learning Studio to develop a linear regression model. You perform an experiment to assess various algorithms.\n\nWhich of the following is an algorithm that reduces the variances between actual and predicted values?",
        "options": [
            {
                "id": "A",
                "text": "Fast Forest Quantile Regression",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Poisson Regression",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Boosted Decision Tree Regression",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Linear Regression",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: C.\nCommunity:\n70% for D\n25% for C\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_98f58094b7e34b4a9e94ccc7fe46b069",
        "type": "multiple_choice_single_answer",
        "question": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nYou are using Azure Machine Learning to run an experiment that trains a classification model.\n\nYou want to use Hyperdrive to find parameters that optimize the AUC metric for the model. You configure a `HyperDriveConfig` for the experiment by running the following code:\n\n```\n\nhyperdrive = HyperDriveConfig(\n    estimator=your_estimator,\n    hyperparameter_sampling=your_params,\n    policy=policy,\n    primary_metric_name='AUC',\n    primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n    max_total_runs=6,\n    max_concurrent_runs=4\n)\n\n```\n\n\nYou plan to use this configuration to run a script that trains a random forest model and then tests it with validation data. The label values for the validation data are stored in a variable named `y_test` variable, and the predicted probabilities from the model are stored in a variable named `y_predicted`.\n\nYou need to add logging to the script to allow Hyperdrive to optimize hyperparameters for the AUC metric.\n\n**Proposed solution**\n\n Run the following code:\n\n```\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score\n# code to train model omitted\nauc = roc_auc_score(y_test, y predicted)\nprint(np.float(auc))\n\n```\n\nDoes the solution meet the goal?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_58419e79c86745c39cd6cdb7d7ccd221",
        "type": "multiple_choice_single_answer",
        "question": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\n\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nAn IT department creates the following Azure resource groups and resources:\n\nan Azure Machine Leaming workspace named amlworkspace an Azure Storage account named amlworkspace12345 an Application Insights instance named amlworkspace54321\nan Azure Key Vault named amliworkspace67890 an Azure Container Registry named amlworkspace09876\n\nA virtual machine named mlivm with the following configuration:\n\ngeneral_compute\n\nOperating system: Ubuntu Linux\nSoftware installed: Python 3.6 and Jupyter Notebooks\n\nThe IT department creates an Azure Kubernetes Service (AKS)-based inference compute target named aks-cluster in the Azure Machine Learning workspace.\n\nYou have a Microsoft Surface Book computer with a GPU. Python 3.6 and Visual Studio Code are installed.\n\nYou need to run a script that trains a deep neural network (DNN) model and logs the loss and accuracy metrics.\n\nSolution: Attach the mlvm virtual machine as a compute target in the Azure Machine Learning workspace. Install the Azure ML SDK on the Surface\n\nBook and run\n\nPython code to connect to the workspace. Run the training script as an experiment on the mlvm remote compute resource.\n\nDoes the solution meet the goal?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_9f97eba51365471f89b0f5c7a8dd0348",
        "type": "multiple_choice_single_answer",
        "question": "You register a file dataset named csv_folder that references a folder. The folder includes multiple comma-separated values (CSV) files in an Azure storage blob container.\n\nYou plan to use the following code to run a script that loads data from the file dataset. You create and instantiate the following variables:\n\nVariable Description remote_cluster References the Azure Machine Learning compute cluster\n\n| ws References the Azure Machine Learning workspace\n\n\n\nYou have the following code:\n\nfrom azureml.train.estimator import Estimator\nfile_dataset = ws.datasets.get('csv_folder')\nestimator = Estimator(source_directory=script_folder,\n\ncompute_target = remote_cluster,\nentry_script ='script.py')\n\nrun = experiment.submit(config=estimator)\nrun.wait_for_completion(show_output=True)\n\n\nYou need to pass the dataset to ensure that the script can read the files it references.\n\nWhich code segment should you insert to replace the code comment?",
        "options": [
            {
                "id": "A",
                "text": "inputs=[file_dataset.as_named_input('training_files')],",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "inputs=[file_dataset.as_named_input('training_files').as_mount()],",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "inputs=[file_dataset.as_named_input('training_files').to_pandas_dataframe()],",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "script_params={'--training_files': file_dataset},",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_a1876461d2fe4facbdf3b085556da83d",
        "type": "multiple_choice_single_answer",
        "question": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution. modelfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nYou create an Azure Machine Learning service datastore in a workspace. The datastore contains the following files:\n\n\u2711 /data/2018/Q1.csv\n\n\u2711 /data/2018/Q2.csv\n\n\u2711 /data/2018/Q3.csv\n\n\u2711 /data/2018/Q4.csv\n\n\u2711 /data/2019/Q1.csv modelll files store data in the following format:\n\nid,f1,f2,I\n\n1,1,2,0\n\n2,1,1,1\n\n3,2,1,0\n\n4,2,2,1\n\nYou run the following code:\n\ndata_store = Datastore.register_azure_blob_container (workspace=ws,\ndatastore_name= 'data_store\u2019,\ncontainer_name= 'quarterly data\u2019,\naccount_name= 'companydata\u2019,\naccount_key=\u2019 NRPxk8duxbM3...\u2019\ncreate_if_ not_exists=False)\n\n\nYou need to create a dataset named training_data and load the data from all files into a single data frame by using the following code:\n\nSolution: Run the following code:\n\nDoes the solution meet the goal?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_511aca8c2a2c4c0aae16f1dd7b6ce7c7",
        "type": "multiple_choice_single_answer",
        "question": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution. modelfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nYou are using Azure Machine Learning to run an experiment that trains a classification model.\n\nYou want to use Hyperdrive to find parameters that optimize the AUC metric for the model. You configure a HyperDriveConfig for the experiment by running the following code:\n\nhyperdrive = HyperDriveConfig(estimator=your_estimator,\nhyperparameter_sampling=your_params,\n\npolicy=policy,\n\nprimary_metric_name=\"AUC',\nprimary_metric_goal=PrimaryMetricGoal .MAXIMIZE,\nmax_total_runs=6,\n\nmax_concurrent_runs=4)\n\n\nYou plan to use this configuration to run a script that trains a random forest model and then tests it with validation data. The label values for the validation data are stored in a variable named y_test variable, and the predicted probabilities from the model are stored in a variable named y_predicted.\n\nYou need to add logging to the script to allow Hyperdrive to optimize hyperparameters for the AUC metric.\n\n**Proposed solution**\n\n Run the following code:\n\n```\nfrom sklearn.metrics import roc_auc_score\nimport logging\n\n#code to train model omitted\nauc = roc_auc_score(y_test, y predicted)\nlogging.info(\"AUC: \" + str(auc))\n```\n\nDoes the solution meet the goal?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: A.\nCommunity:\n100% for B\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_23323466f16740eda1f6dfbd43c41721",
        "type": "multiple_choice_single_answer",
        "question": "You make use of Azure Machine Learning Studio to create a binary classification model.\n\nYou are preparing to carry out a parameter sweep of the model to tune hyperparameters. You have to make sure that the sweep allows for every possible combination of hyperparameters to be iterated. Also, the computing resources needed to carry out the sweep must be reduced.\n\nWhich of the following actions should you take?",
        "options": [
            {
                "id": "A",
                "text": "You should consider making use of the Selective grid sweep mode.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "You should consider making use of the Measured grid sweep mode.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "You should consider making use of the Entire grid sweep mode.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "You should consider making use of the Random grid sweep mode.",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_bca8e25f08fc450d8c5e82dab13995f6",
        "type": "multiple_choice_single_answer",
        "question": "You are developing deep learning models to analyze semi-structured, unstructured, and structured data types.\n\nYou have the following data available for model building:\n\n\u2711 Video recordings of sporting events\n\n\u2711 Transcripts of radio commentary about events\n\n\u2711 Logs from related social media feeds captured during sporting events\n\nYou need to select an environment for creating the model.\n\nWhich environment should you use?",
        "options": [
            {
                "id": "A",
                "text": "Azure Cognitive Services",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Azure Data Lake Analytics",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Azure HDInsight with Spark MLib",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Azure Machine Learning Studio",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_91758c189e014ef3bd3e07e3203f8f73",
        "type": "multiple_choice_single_answer",
        "question": "You register a model that you plan to use in a batch inference pipeline.\n\nThe batch inference pipeline must use a ParallelRunStep step to process files in a file dataset. The script has the ParallelRunStep step runs must process six input files each time the inferencing function is called.\n\nYou need to configure the pipeline.\n\nWhich configuration setting should you specify in the ParallelRunConfig object for the PrallelRunStep step?",
        "options": [
            {
                "id": "A",
                "text": "process_count_per_node= \"6\"",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "node_count= \"6\"",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "mini_batch_size= \"6\"",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "error_threshold= \"6\"",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: B.\nCommunity:\n100% for (100%)\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_a5d3bcd32ce94565b2cb7d961ca9db81",
        "type": "multiple_choice_multiple_answer",
        "question": "You must store data in Azure Blob Storage to support Azure Machine Learning.\n\nYou need to transfer the data into Azure Blob Storage.\n\nWhat are three possible ways to achieve the goal? Each correct answer presents a complete solution.\n\nNOTE: Each correct selection is worth one point.",
        "options": [
            {
                "id": "A",
                "text": "Bulk Insert SQL Query",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "AzCopy",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Python script",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Azure Storage Explorer",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "E",
                "text": "Bulk Copy Program (BCP)",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_2a4661a5fc414670b99b70443a1749ab",
        "type": "multiple_choice_single_answer",
        "question": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution. modelfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nYou create an Azure Machine Learning service datastore in a workspace. The datastore contains the following files:\n\n\u2711 /data/2018/Q1.csv\n\n\u2711 /data/2018/Q2.csv\n\n\u2711 /data/2018/Q3.csv\n\n\u2711 /data/2018/Q4.csv\n\n\u2711 /data/2019/Q1.csv\n\nAll files store data in the following format:\n\nid,f1,f2,I\n\n1,1,2,0\n\n2,1,1,1\n\n3,2,1,0\n\n4,2,2,1\n\nYou run the following code:\n\ndata_store = Datastore.register_azure_blob_container (workspace=ws,\ndatastore_name= 'data_store\u2019,\ncontainer_name= 'quarterly data\u2019,\naccount_name= 'companydata\u2019,\naccount_key=\u2019 NRPxk8duxbM3...\u2019\ncreate_if_ not_exists=False)\n\n\nYou need to create a dataset named training_data and load the data from all files into a single data frame by using the following code:\n\nSolution: Run the following code:\n\nDoes the solution meet the goal?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_60e06d92e00a4afb8c2cc22b2a9d5c29",
        "type": "multiple_choice_single_answer",
        "question": "You use the Azure Machine Learning designer to create and run a training pipeline. You then create a real-time inference pipeline.\n\nYou must deploy the real-time inference pipeline as a web service.\n\nWhat must you do before you deploy the real-time inference pipeline?",
        "options": [
            {
                "id": "A",
                "text": "Run the real-time inference pipeline.",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Create a batch inference pipeline.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Clone the training pipeline.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Create an Azure Machine Learning compute cluster.",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: D.\nCommunity:\n59% for A\n41% for D\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_9006366d144746679d453b99541c6215",
        "type": "multiple_choice_single_answer",
        "question": "This question is included in a number of questions that depicts the identical set-up. However, every question has a distinctive result. Establish if the recommendation satisfies the requirements.\n\nYou are in the process of carrying out feature engineering on a dataset.\n\nYou want to add a feature to the dataset and fill the column value.\n\nRecommendation: You must make use of the Group Categorical Values Azure Machine Learning Studio module.\n\nWill the requirements be satisfied?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_6455abb427664db5b88e34212b46120f",
        "type": "multiple_choice_multiple_answer",
        "question": "You train and register a model in your Azure Machine Learning workspace.\n\nYou must publish a pipeline that enables client applications to use the model for batch inferencing. You must use a pipeline with a single\n\nParallelRunStep step that runs a Python inferencing script to get predictions from the input data.\n\nYou need to create the inferencing script for the ParallelRunStep pipeline step.\n\nWhich two functions should you include? Each correct answer presents part of the solution.\n\nNOTE: Each correct selection is worth one point.",
        "options": [
            {
                "id": "A",
                "text": "run(mini_batch)",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "main()",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "batch()",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "init()",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "E",
                "text": "score(mini_batch)",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_fcdb864e92ec4421a4861878ddec009e",
        "type": "multiple_choice_single_answer",
        "question": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\n\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nYou have a Python script named train.py in a local folder named scripts. The script trains a regression model by using scikit-learn. The script includes code to load a training data file which is also located in the scripts folder.\n\nYou must run the script as an Azure ML experiment on a compute cluster named aml-compute.\n\nYou need to configure the run to ensure that the environment includes the required packages for model training. You have instantiated a variable named aml- compute that references the target compute cluster.\n\nSolution: Run the following code:\n\nfrom azureml.train.sklearn import SKLearn\nsk_est = SKLearn(source_directory='./scripts',\ncompute_target=aml-compute,\nentry_script='train.py')\n\n\nDoes the solution meet the goal?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: A.\nCommunity:\n100% for B\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_8ed32327d5e24a35892c4cf71d758b72",
        "type": "multiple_choice_single_answer",
        "question": "Your team is building a data engineering and data science development environment.\n\nThe environment must support the following requirements:\n\n\u2711 support Python and Scala\n\n\u2711 compose data storage, movement, and processing services into automated data pipelines\n\n\u2711 the same tool should be used for the orchestration of both data engineering and data science\n\n\u2711 support workload isolation and interactive workloads\n\n\u2711 enable scaling across a cluster of machines\n\nYou need to create the environment.\n\nWhat should you do?",
        "options": [
            {
                "id": "A",
                "text": "Build the environment in Apache Hive for HDInsight and use Azure Data Factory for orchestration.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Build the environment in Azure Databricks and use Azure Data Factory for orchestration.",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Build the environment in Apache Spark for HDInsight and use Azure Container Instances for orchestration.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Build the environment in Azure Databricks and use Azure Container Instances for orchestration.",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_88cb255b3d264144973dfc8a088793e3",
        "type": "multiple_choice_single_answer",
        "question": "You are a data scientist creating a linear regression model.\n\nYou need to determine how closely the data fits the regression line.\n\nWhich metric should you review?",
        "options": [
            {
                "id": "A",
                "text": "Root Mean Square Error",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Coeficient of determination",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Recall",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Precision",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "E",
                "text": "Mean absolute error",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_c21d257e0d774fdcacaf8007e1650c92",
        "type": "multiple_choice_single_answer",
        "question": "Case study \nOverview \nYou are a data scientist in a company that provides data science for professional sporting events. Models will use global and local market data to meet the following business goals:\n\nUnderstand sentiment of mobile device users at sporting events based on audio from crowd reactions.\n\nAssess a user's tendency to respond to an advertisement.\n\nCustomize styles of ads served on mobile devices.\n\nUse video to detect penalty events\n\nCurrent environment \nMedia used for penalty event detection will be provided by consumer devices. Media may include images and videos captured during the sporting event and shared using social media. The images and videos will have varying sizes and formats.\n\nThe data available for model building comprises of seven years of sporting event media. The sporting event media includes; recorded video transcripts or radio commentary, and logs from related social media feeds captured during the sporting events.\n\nCrowd sentiment will include audio recordings submitted by event attendees in both mono and stereo formats.\n\nPenalty detection and sentiment \nData scientists must build an intelligent solution by using multiple machine learning models for penalty event detection.\n\nData scientists must build notebooks in a local environment using automatic feature engineering and model building in machine learning pipelines.\n\nNotebooks must be deployed to retrain by using Spark instances with dynamic worker allocation.\n\nNotebooks must execute with the same code on new Spark instances to recode only the source of the data.\n\nGlobal penalty detection models must be trained by using dynamic runtime graph computation during training.\n\nLocal penalty detection models must be written by using BrainScript.\n\nExperiments for local crowd sentiment models must combine local penalty detection data.\n\nCrowd sentiment models must identify known sounds such as cheers and known catch phrases. Individual crowd sentiment models will detect similar sounds.\n\nAll shared features for local models are continuous variables.\n\nShared features must use double precision. Subsequent layers must have aggregate running mean and standard deviation metrics available.\n\nAdvertisements \nDuring the initial weeks in production, the following was observed:\n\nAd response rated declined.\n\nDrops were not consistent across ad styles.\n\nThe distribution of features across training and production data are not consistent\n\nAnalysis shows that, of the 100 numeric features on user location and behavior, the 47 features that come from location sources are being used as raw features. A suggested experiment to remedy the bias and variance issue is to engineer 10 linearly uncorrelated features.\n\nInitial data discovery shows a wide range of densities of target states in training data used for crowd sentiment models.\n\nAll penalty detection models show inference phases using a Stochastic Gradient Descent (SGD) are running too slow.\n\nAudio samples show that the length of a catch phrase varies between 25%-47% depending on region\n\nThe performance of the global penalty detection models shows lower variance but higher bias when comparing training and validation sets.\n\nBefore implementing any feature changes, you must confirm the bias and variance using all training and validation cases.\n\nAd response models must be trained at the beginning of each event and applied during the sporting event.\n\nMarket segmentation models must optimize for similar ad response history.\n\nSampling must guarantee mutual and collective exclusively between local and global segmentation models that share the same features.\n\nLocal market segmentation models will be applied before determining a user's propensity to respond to an advertisement.\n\nAd response models must support non-linear boundaries of features.\n\nThe ad propensity model uses a cut threshold is 0.45 and retrains occur if weighted Kappa deviated from 0.1 +/- 5%.\n\nThe ad propensity model uses cost factors shown in the following diagram:\n\nActual\n\nPa}IPald\n\n\n\nThe ad propensity model uses proposed cost factors shown in the following diagram:\n\nActual\n\nPa}1Pald\n\n\n\nPerformance curves of current and proposed cost factor scenarios are shown in the following diagram:\n\nScenario\n\u00ab Scenario1\n\nScenario2\n\n\u00a2Scenario3\n\n\nYou need to implement a scaling strategy for the local penalty detection data.\n\nWhich normalization type should you use?",
        "options": [
            {
                "id": "A",
                "text": "Streaming",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Weight",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Batch",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Cosine",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_739887cd6eeb410fabb37b8f795dd971",
        "type": "multiple_choice_single_answer",
        "question": "You have a dataset that contains salary information for users. You plan to generate an aggregate salary report that shows average salaries by city.\n\nPrivacy of individuals must be preserved without impacting accuracy, completeness, or reliability of the data. The aggregation must be statistically consistent with the distribution of the original data. You must return an approximation of the data instead of the raw data.\n\nYou need to apply a differential privacy approach.\n\nWhat should you do?",
        "options": [
            {
                "id": "A",
                "text": "Add noise to the salary data during the analysis",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Encrypt the salary data before analysis",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Remove the salary data",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Convert the salary data to the average column value",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: D.\nCommunity:\n100% for A\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_2062c63a92d5410bb695c9c63d92b3dd",
        "type": "multiple_choice_single_answer",
        "question": "You are a lead data scientist for a project that tracks the health and migration of birds. You create a multi-class image classification deep learning model that uses a set of labeled bird photographs collected by experts.\n\nYou have 100,000 photographs of birds. All photographs use the JPG format and are stored in an Azure blob container in an Azure subscription.\n\nYou need to access the bird photograph files in the Azure blob container from the Azure Machine Learning service workspace that will be used for deep learning model training. You must minimize data movement.\n\nWhat should you do?",
        "options": [
            {
                "id": "A",
                "text": "Create an Azure Data Lake store and move the bird photographs to the store.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Create an Azure Cosmos DB database and attach the Azure Blob containing bird photographs storage to the database.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Create and register a dataset by using TabularDataset class that references the Azure blob storage containing bird photographs.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Register the Azure blob storage containing the bird photographs as a datastore in Azure Machine Learning service.",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "E",
                "text": "Copy the bird photographs to the blob datastore that was created with your Azure Machine Learning service workspace.",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_6ccb3ec185b94fc8a4ba75a13fd89ce9",
        "type": "multiple_choice_single_answer",
        "question": "Case study \nOverview \nYou are a data scientist in a company that provides data science for professional sporting events. Models will use global and local market data to meet the following business goals:\n\nUnderstand sentiment of mobile device users at sporting events based on audio from crowd reactions.\n\nAssess a user's tendency to respond to an advertisement.\n\nCustomize styles of ads served on mobile devices.\n\nUse video to detect penalty events\n\nCurrent environment \nMedia used for penalty event detection will be provided by consumer devices. Media may include images and videos captured during the sporting event and shared using social media. The images and videos will have varying sizes and formats.\n\nThe data available for model building comprises of seven years of sporting event media. The sporting event media includes; recorded video transcripts or radio commentary, and logs from related social media feeds captured during the sporting events.\n\nCrowd sentiment will include audio recordings submitted by event attendees in both mono and stereo formats.\n\nPenalty detection and sentiment \nData scientists must build an intelligent solution by using multiple machine learning models for penalty event detection.\n\nData scientists must build notebooks in a local environment using automatic feature engineering and model building in machine learning pipelines.\n\nNotebooks must be deployed to retrain by using Spark instances with dynamic worker allocation.\n\nNotebooks must execute with the same code on new Spark instances to recode only the source of the data.\n\nGlobal penalty detection models must be trained by using dynamic runtime graph computation during training.\n\nLocal penalty detection models must be written by using BrainScript.\n\nExperiments for local crowd sentiment models must combine local penalty detection data.\n\nCrowd sentiment models must identify known sounds such as cheers and known catch phrases. Individual crowd sentiment models will detect similar sounds.\n\nAll shared features for local models are continuous variables.\n\nShared features must use double precision. Subsequent layers must have aggregate running mean and standard deviation metrics available.\n\nAdvertisements \nDuring the initial weeks in production, the following was observed:\n\nAd response rated declined.\n\nDrops were not consistent across ad styles.\n\nThe distribution of features across training and production data are not consistent\n\nAnalysis shows that, of the 100 numeric features on user location and behavior, the 47 features that come from location sources are being used as raw features. A suggested experiment to remedy the bias and variance issue is to engineer 10 linearly uncorrelated features.\n\nInitial data discovery shows a wide range of densities of target states in training data used for crowd sentiment models.\n\nAll penalty detection models show inference phases using a Stochastic Gradient Descent (SGD) are running too slow.\n\nAudio samples show that the length of a catch phrase varies between 25%-47% depending on region\n\nThe performance of the global penalty detection models shows lower variance but higher bias when comparing training and validation sets.\n\nBefore implementing any feature changes, you must confirm the bias and variance using all training and validation cases.\n\nAd response models must be trained at the beginning of each event and applied during the sporting event.\n\nMarket segmentation models must optimize for similar ad response history.\n\nSampling must guarantee mutual and collective exclusively between local and global segmentation models that share the same features.\n\nLocal market segmentation models will be applied before determining a user's propensity to respond to an advertisement.\n\nAd response models must support non-linear boundaries of features.\n\nThe ad propensity model uses a cut threshold is 0.45 and retrains occur if weighted Kappa deviated from 0.1 +/- 5%.\n\nThe ad propensity model uses cost factors shown in the following diagram:\n\nActual\n\nPa}IPald\n\n\n\nThe ad propensity model uses proposed cost factors shown in the following diagram:\n\nActual\n\nPa}1Pald\n\n\n\nPerformance curves of current and proposed cost factor scenarios are shown in the following diagram:\n\nScenario\n\u00ab Scenario1\n\nScenario2\n\n\u00a2Scenario3\n\n\nYou need to implement a new cost factor scenario for the ad response models as illustrated in the performance curve exhibit.\n\nWhich technique should you use?",
        "options": [
            {
                "id": "A",
                "text": "Set the threshold to 0.5 and retrain if weighted Kappa deviates +/- 5% from 0.45.",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Set the threshold to 0.05 and retrain if weighted Kappa deviates +/- 5% from 0.5.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Set the threshold to 0.2 and retrain if weighted Kappa deviates +/- 5% from 0.6.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Set the threshold to 0.75 and retrain if weighted Kappa deviates +/- 5% from 0.15.",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_63df506ce42f468d8d0c064afdf2a205",
        "type": "multiple_choice_single_answer",
        "question": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\n\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nYou are a data scientist using Azure Machine Learning Studio.\n\nYou need to normalize values to produce an output column into bins to predict a target column.\n\nSolution: Apply an Equal Width with Custom Start and Stop binning mode.\n\nDoes the solution meet the goal?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_d7aefd57df21451b9082c7ba168ba96e",
        "type": "multiple_choice_single_answer",
        "question": "You are creating a new experiment in Azure Machine Learning Studio. You have a small dataset that has missing values in many columns. The data does not require the application of predictors for each column. You plan to use the Clean Missing Data.\n\nYou need to select a data cleaning method.\n\nWhich method should you use?",
        "options": [
            {
                "id": "A",
                "text": "Replace using Probabilistic PCA",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Normalization",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Synthetic Minority Oversampling Technique (SMOTE)",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Replace using MICE",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_6a2c6f049a1d4af8a3af06f1e7718c16",
        "type": "multiple_choice_single_answer",
        "question": "You are performing a filter-based feature selection for a dataset to build a multi-class classifier by using Azure Machine Learning Studio.\n\nThe dataset contains categorical features that are highly correlated to the output label column.\n\nYou need to select the appropriate feature scoring statistical method to identify the key predictors.\n\nWhich method should you use?",
        "options": [
            {
                "id": "A",
                "text": "Kendall correlation",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Spearman correlation",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Chi-squared",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Pearson correlation",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: D.\nCommunity:\n100% for C (100%)\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_3aa523b109624994b87217ec1cda6219",
        "type": "multiple_choice_multiple_answer",
        "question": "You build a data pipeline in an Azure Machine Learning workspace by using the Azure Machine Learning SDK for Python.\n\nYou need to run a Python script as a pipeline step.\n\nWhich two classes could you use? Each correct answer presents a complete solution.\n\nNOTE: Each correct selection is worth one point.",
        "options": [
            {
                "id": "A",
                "text": "PythonScriptStep",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "AutoMLStep",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "CommandStep",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "StepRun",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: CD.\nCommunity:\n100% for AC\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_ccc437c1c3e54375a94c1d88b9aa4e11",
        "type": "multiple_choice_single_answer",
        "question": "You plan to create a compute instance as part of an Azure Machine Learning development workspace.\n\nYou must interactively debug code running on the compute instance by using Visual Studio Code Remote.\n\nYou need to provision the compute instance.\n\nWhat should you do?",
        "options": [
            {
                "id": "A",
                "text": "Enable Remote Desktop Protocol (RDP) access.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Modify role-based access control (RBAC) settings at the workspace level.",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Enable Secure Shell Protocol (SSH) access.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Modify role-based access control (RBAC) settings at the compute instance level.",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_bea58cf7aba64dafa571f6ea348c6217",
        "type": "multiple_choice_single_answer",
        "question": "You are a data scientist working for a bank and have used Azure ML to train and register a machine learning model that predicts whether a customer is likely to repay a loan.\n\nYou want to understand how your model is making selections and must be sure that the model does not violate government regulations such as denying loans based on where an applicant lives.\n\nYou need to determine the extent to which each feature in the customer data is infiuencing predictions.\n\nWhat should you do?",
        "options": [
            {
                "id": "A",
                "text": "Enable data drift monitoring for the model and its training dataset.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Score the model against some test data with known label values and use the results to calculate a confusion matrix.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Use the Hyperdrive library to test the model with multiple hyperparameter values.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Use the interpretability package to generate an explainer for the model.",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "E",
                "text": "Add tags to the model registration indicating the names of the features in the training dataset.",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_07f079bfa64748a5a3b5f246a9345a3c",
        "type": "multiple_choice_single_answer",
        "question": "You have a dataset that is stored in an Azure Machine Learning workspace.\n\nYou must perform a data analysis for differential privacy by using the SmartNoise SDK.\n\nYou need to measure the distribution of reports for repeated queries to ensure that they are balanced.\n\nWhich type of test should you perform?",
        "options": [
            {
                "id": "A",
                "text": "Bias",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Privacy",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Accuracy",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Utility",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: C.\nCommunity:\n50% for D\n43% for A\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_797b380ea8df4a1a97c0441abe0b3098",
        "type": "multiple_choice_multiple_answer",
        "question": "You plan to provision an Azure Machine Learning Basic edition workspace for a data science project.\n\nYou need to identify the tasks you will be able to perform in the workspace.\n\nWhich three tasks will you be able to perform? Each correct answer presents a complete solution.\n\nNOTE: Each correct selection is worth one point.",
        "options": [
            {
                "id": "A",
                "text": "Create a Compute Instance and use it to run code in Jupyter notebooks.",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Create an Azure Kubernetes Service (AKS) inference cluster.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Use the designer to train a model by dragging and dropping pre-defined modules.",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Create a tabular dataset that supports versioning.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "E",
                "text": "Use the Automated Machine Learning user interface to train a model.",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: ABD.\nCommunity:\n100% for ACE\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_c602b0ec0f24452d8cdda175a97a9e29",
        "type": "multiple_choice_multiple_answer",
        "question": "You create a multi-class image classification deep learning model that uses the PyTorch deep learning framework.\n\nYou must configure Azure Machine Learning Hyperdrive to optimize the hyperparameters for the classification model.\n\nYou need to define a primary metric to determine the hyperparameter values that result in the model with the best accuracy score.\n\nWhich three actions must you perform? Each correct answer presents part of the solution.\n\nNOTE: Each correct selection is worth one point.",
        "options": [
            {
                "id": "A",
                "text": "Set the primary_metric_goal of the estimator used to run the bird_classifier_train.py script to maximize.",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Add code to the bird_classifier_train.py script to calculate the validation loss of the model and log it as a fioat value with the key loss.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Set the primary_metric_goal of the estimator used to run the bird_classifier_train.py script to minimize.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Set the primary_metric_name of the estimator used to run the bird_classifier_train.py script to accuracy.",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "E",
                "text": "Set the primary_metric_name of the estimator used to run the bird_classifier_train.py script to loss.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "F",
                "text": "Add code to the bird_classifier_train.py script to calculate the validation accuracy of the model and log it as a fioat value with the key accuracy.",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_9d1e2f4c39484cd48f3417745a625cf1",
        "type": "multiple_choice_single_answer",
        "question": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.After you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nYou are using Azure Machine Learning to run an experiment that trains a classification model.\n\nYou want to use Hyperdrive to find parameters that optimize the AUC metric for the model. You configure a `HyperDriveConfig` for the experiment by running the following code:\n\n```\n\nhyperdrive = HyperDriveConfig(\n    estimator=your_estimator,\n    hyperparameter_sampling=your_params,\n    policy=policy,\n    primary_metric_name='AUC',\n    primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n    max_total_runs=6,\n    max_concurrent_runs=4\n)\n\n```\n\n\nYou plan to use this configuration to run a script that trains a random forest model and then tests it with validation data. The label values for the validation data are stored in a variable named `y_test` variable, and the predicted probabilities from the model are stored in a variable named `y_predicted`.\n\nYou need to add logging to the script to allow Hyperdrive to optimize hyperparameters for the AUC metric.\n\n**Proposed solution**\n\n Run the following code:\n\n```import json\nimport os\nfrom sklearn.metrics import roc_auc_score\n# code to train model omitted\nauc = roc_auc_score(y_ test, y_ predicted)\nos.makedirs(\"outputs\", exist_ok=True)\nwith open(\"outputs/AUC.txt\", \"w\") as fp:\n    fp.write(auc)\n\n```\n\nDoes the solution meet the goal",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_6bc92c75fa68466086ab81b8e79fbcc6",
        "type": "multiple_choice_single_answer",
        "question": "This question is included in a number of questions that depicts the identical set-up. However, every question has a distinctive result. Establish if the recommendation satisfies the requirements.\n\nYou are in the process of creating a machine learning model. Your dataset includes rows with null and missing values.\n\nYou plan to make use of the Clean Missing Data module in Azure Machine Learning Studio to detect and fix the null and missing values in the dataset.\n\nRecommendation: You make use of the Remove entire row option.\n\nWill the requirements be satisfied?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_f3275d9d02b041028f269aa5270fc1d7",
        "type": "multiple_choice_single_answer",
        "question": "You train and register a machine learning model. You create a batch inference pipeline that uses the model to generate predictions from multiple data files.\n\nYou must publish the batch inference pipeline as a service that can be scheduled to run every night.\n\nYou need to select an appropriate compute target for the inference service.\n\nWhich compute target should you use?",
        "options": [
            {
                "id": "A",
                "text": "Azure Machine Learning compute instance",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Azure Machine Learning compute cluster",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Azure Kubernetes Service (AKS)-based inference cluster",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Azure Container Instance (ACI) compute target",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_1aa9fcb1714c4f01a3899de4d38b3d77",
        "type": "multiple_choice_single_answer",
        "question": "You are solving a classification task.\n\nYou must evaluate your model on a limited data sample by using k-fold cross-validation. You start by configuring a k parameter as the number of splits.\n\nYou need to configure the k parameter for the cross-validation.\n\nWhich value should you use?",
        "options": [
            {
                "id": "A",
                "text": "k=0.5",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "k=0.01",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "k=5",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "k=1",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_5a94ebd220b94c3dbe1dd1276c1bd65a",
        "type": "multiple_choice_single_answer",
        "question": "You are performing feature engineering on a dataset.\n\nYou must add a feature named CityName and populate the column value with the text London.\n\nYou need to add the new feature to the dataset.\n\nWhich Azure Machine Learning Studio module should you use?",
        "options": [
            {
                "id": "A",
                "text": "Extract N-Gram Features from Text",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Edit Metadata",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Preprocess Text",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Apply SQL Transformation",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: B.\nCommunity:\n78% for D\n22% for B\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_49a31b55c7b14833828cf5ffe5e1b6ad",
        "type": "multiple_choice_single_answer",
        "question": "You are implementing hyperparameter tuning for a model training from a notebook. The notebook is in an Azure Machine Learning workspace.\n\nYou must configure a grid sampling method over the search space for the num_hidden_layers and batch_size hyperparameters.\n\nYou need to identify the hyperparameters for the grid sampling.\n\nWhich hyperparameter sampling approach should you use?",
        "options": [
            {
                "id": "A",
                "text": "uniform",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "qlognormal",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "choice",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "normal",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: B.\nCommunity:\n100% for (100%)\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_6ef8f8e895f44e74b2e312a222f0c14a",
        "type": "multiple_choice_single_answer",
        "question": "You create a binary classification model by using Azure Machine Learning Studio.\n\nYou must tune hyperparameters by performing a parameter sweep of the model. The parameter sweep must meet the following requirements:\n\n\u2711 iterate all possible combinations of hyperparameters\n\n\u2711 minimize computing resources required to perform the sweep\n\nYou need to perform a parameter sweep of the model.\n\nWhich parameter sweep mode should you use?",
        "options": [
            {
                "id": "A",
                "text": "Random sweep",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Sweep clustering",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Entire grid",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Random grid",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_ec5b56f7b75545fbbff641220d40bcbd",
        "type": "multiple_choice_single_answer",
        "question": "You plan to build a team data science environment. Data for training models in machine learning pipelines will be over 20 GB in size.\n\nYou have the following requirements:\n\n\u2711 Models must be built using Caffe2 or Chainer frameworks.\n\n\u2711 Data scientists must be able to use a data science environment to build the machine learning pipelines and train models on their personal devices in both connected and disconnected network environments.\n\nPersonal devices must support updating machine learning pipelines when connected to a network.\n\nYou need to select a data science environment.\n\nWhich environment should you use?",
        "options": [
            {
                "id": "A",
                "text": "Azure Machine Learning Service",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Azure Machine Learning Studio",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Azure Databricks",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Azure Kubernetes Service (AKS)",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_cf271f1f19f54ed9a5c192df086f25c6",
        "type": "multiple_choice_single_answer",
        "question": "You plan to use automated machine learning to train a regression model. You have data that has features which have missing values, and categorical features with few distinct values.\n\nYou need to configure automated machine learning to automatically impute missing values and encode categorical features as part of the training task.\n\nWhich parameter and value pair should you use in the AutoMLConfig class?",
        "options": [
            {
                "id": "A",
                "text": "featurization = 'auto'",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "enable_voting_ensemble = True",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "task = 'classification'",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "exclude_nan_labels = True",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "E",
                "text": "enable_tf = True",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_d47e9d74efb54f52b7946290d3f07adf",
        "type": "multiple_choice_single_answer",
        "question": "This question is included in a number of questions that depicts the identical set-up. However, every question has a distinctive result. Establish if the recommendation satisfies the requirements.\n\nYou have been tasked with employing a machine learning model, which makes use of a PostgreSQL database and needs GPU processing, to forecast prices.\n\nYou are preparing to create a virtual machine that has the necessary tools built into it.\n\nYou need to make use of the correct virtual machine type.\n\nRecommendation: You make use of a Deep Learning Virtual Machine (DLVM) Windows edition.\n\nWill the requirements be satisfied?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: B.\nCommunity:\n88% for A\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_0b2cede3864f4d929c6194f08294ad28",
        "type": "multiple_choice_single_answer",
        "question": "You need to implement a Data Science Virtual Machine (DSVM) that supports the Caffe2 deep learning framework.\n\nWhich of the following DSVM should you create?",
        "options": [
            {
                "id": "A",
                "text": "Windows Server 2012 DSVM",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Windows Server 2016 DSVM",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Ubuntu 16.04 DSVM",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "CentOS 7.4 DSVM",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_f364cf8c51e543019ec4a9eecde5889a",
        "type": "multiple_choice_single_answer",
        "question": "This question is included in a number of questions that depicts the identical set-up. However, every question has a distinctive result. Establish if the recommendation satisfies the requirements.\n\nYou are in the process of creating a machine learning model. Your dataset includes rows with null and missing values.\n\nYou plan to make use of the Clean Missing Data module in Azure Machine Learning Studio to detect and fix the null and missing values in the dataset.\n\nRecommendation: You make use of the Replace with median option.\n\nWill the requirements be satisfied?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: B.\nCommunity:\n74% for A\n26% for B\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_0d6b04020df443f59d54bd497ecd95d8",
        "type": "multiple_choice_single_answer",
        "question": "You use Azure Machine Learning Studio to build a machine learning experiment.\n\nYou need to divide data into two distinct datasets.\n\nWhich module should you use?",
        "options": [
            {
                "id": "A",
                "text": "Split Data",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Load Trained Model",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Assign Data to Clusters",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Group Data into Bins",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: D.\nCommunity:\n81% for A\n19% for D\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_05f39a0b4cd0438eb5798f355c90d0dd",
        "type": "multiple_choice_single_answer",
        "question": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\n\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nYou are analyzing a numerical dataset which contains missing values in several columns.\n\nYou must clean the missing values using an appropriate operation without affecting the dimensionality of the feature set.\n\nYou need to analyze a full dataset to include all values.\n\nSolution: Calculate the column median value and use the median value as the replacement for any missing value in the column.\n\nDoes the solution meet the goal?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: B.\nCommunity:\n90% for A\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_a4780749d14542d3b051a117795c8bad",
        "type": "multiple_choice_single_answer",
        "question": "You have the following code. The code prepares an experiment to run a script:\n\nfrom azureml.core import Workspace, Experiment, Run, ScriptRunConfig\n\nws = Workspace. from_config()\n\nscript_config = ScriptRunConfig(source_directory=\u2018experiment_files\u2019,\nscript=\u2018experiment.py\u2019 )\n\nscript_experiment = Experiment(workspace=ws, name=\u2018script-experiment? )\n\n\nThe experiment must be run on local computer using the default environment.\n\nYou need to add code to start the experiment and run the script.\n\nWhich code segment should you use?",
        "options": [
            {
                "id": "A",
                "text": "run = script_experiment.start_logging()",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "run = Run(experiment=script_experiment)",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "ws.get_run(run_id=experiment.id)",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "run = script_experiment.submit(config=script_config)",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_54720b4bb03a4ecbab3d34c3b7ea5ed8",
        "type": "multiple_choice_single_answer",
        "question": "You are solving a classification task.\n\nThe dataset is imbalanced.\n\nYou need to select an Azure Machine Learning Studio module to improve the classification accuracy.\n\nWhich module should you use?",
        "options": [
            {
                "id": "A",
                "text": "Permutation Feature Importance",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Filter Based Feature Selection",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Fisher Linear Discriminant Analysis",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Synthetic Minority Oversampling Technique (SMOTE)",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_64be73d0e5d44e50b814636dbaf5a0a3",
        "type": "multiple_choice_single_answer",
        "question": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\n\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nYou train a classification model by using a logistic regression algorithm.\n\nYou must be able to explain the model's predictions by calculating the importance of each feature, both as an overall global relative importance value and as a measure of local importance for a specific set of predictions.\n\nYou need to create an explainer that you can use to retrieve the required global and local feature importance values.\n\nSolution: Create a MimicExplainer.\n\nDoes the solution meet the goal?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: B.\nCommunity:\n100% for A\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_be61351c1a444325863d09701f387adb",
        "type": "multiple_choice_multiple_answer",
        "question": "You have been tasked with ascertaining if two sets of data differ considerably. You will make use of Azure Machine Learning Studio to complete your task.\n\nYou plan to perform a paired t-test.\n\nWhich of the following are conditions that must apply to use a paired t-test? (Choose all that apply.)",
        "options": [
            {
                "id": "A",
                "text": "All scores are independent from each other.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "You have a matched pairs of scores.",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "The sampling distribution of d is normal.",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "The sampling distribution of x1- x2 is normal.",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_cbe0129746b346a6846d0daaa319a260",
        "type": "multiple_choice_single_answer",
        "question": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\n\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nYou train and register a machine learning model.\n\nYou plan to deploy the model as a real-time web service. Applications must use key-based authentication to use the model.\n\nYou need to deploy the web service.\n\nSolution:\n\nCreate an AciWebservice instance.\n\nSet the value of the ssl_enabled property to True.\n\nDeploy the model to the service.\n\nDoes the solution meet the goal?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_5c836eadbe734f3f94e871b9be7a1fca",
        "type": "multiple_choice_single_answer",
        "question": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\n\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nAn IT department creates the following Azure resource groups and resources:\n\nan Azure Machine Leaming workspace named amlworkspace\nan Azure Storage account named amlworkspace12345\n\nan Application Insights instance named amlworkspace54321\nan Azure Key Vault named amliworkspace67890, an Azure Container Registry named amlworkspace09876\n\nA virtual machine named mlivm with the following configuration:\n\ngeneral_compute\n\nOperating system: Ubuntu Linux\nSoftware installed: Python 3.6 and Jupyter Notebooks\n\n\n\nThe IT department creates an Azure Kubernetes Service (AKS)-based inference compute target named aks-cluster in the Azure Machine Learning workspace.\n\nYou have a Microsoft Surface Book computer with a GPU. Python 3.6 and Visual Studio Code are installed.\n\nYou need to run a script that trains a deep neural network (DNN) model and logs the loss and accuracy metrics.\n\nSolution: Install the Azure ML SDK on the Surface Book. Run Python code to connect to the workspace and then run the training script as an experiment on local compute.\n\nDoes the solution meet the goal?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: B.\nCommunity:\n100% for A\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_2089276a49de4739aca247e18b4c3444",
        "type": "multiple_choice_single_answer",
        "question": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\n\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nYou are a data scientist using Azure Machine Learning Studio.\n\nYou need to normalize values to produce an output column into bins to predict a target column.\n\nSolution: Apply a Quantiles normalization with a QuantileIndex normalization.\n\nDoes the solution meet the goal?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: B.\nCommunity:\n67% for A\n33% for B\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_92d188dc26094c55ac3ae58fe4984d76",
        "type": "multiple_choice_single_answer",
        "question": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\n\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nYou are using Azure Machine Learning Studio to perform feature engineering on a dataset.\n\nYou need to normalize values to produce a feature column grouped into bins.\n\nSolution: Apply an Entropy Minimum Description Length (MDL) binning mode.\n\nDoes the solution meet the goal?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: A.\nCommunity:\n100% for B\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_5bc25dcdb3184995b4eb088bd2244844",
        "type": "multiple_choice_single_answer",
        "question": "You are with a time series dataset in Azure Machine Learning Studio.\n\nYou need to split your dataset into training and testing subsets by using the Split Data module.\n\nWhich splitting mode should you use?",
        "options": [
            {
                "id": "A",
                "text": "Recommender Split",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Regular Expression Split",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Relative Expression Split",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Split Rows with the Randomized split parameter set to true",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: D.\nCommunity:\n83% for C\n17% for D\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_1ece7b80f89c4e5da7b0599247b50e4a",
        "type": "multiple_choice_single_answer",
        "question": "You are developing a data science workspace that uses an Azure Machine Learning service.\n\nYou need to select a compute target to deploy the workspace.\n\nWhat should you use?",
        "options": [
            {
                "id": "A",
                "text": "Azure Data Lake Analytics",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Azure Databricks",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Azure Container Service",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Apache Spark for HDInsight",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_538668590d6f45d7aab5168b4ee1ef28",
        "type": "multiple_choice_single_answer",
        "question": "You construct a machine learning experiment via Azure Machine Learning Studio.\n\nYou would like to split data into two separate datasets.\n\nWhich of the following actions should you take?",
        "options": [
            {
                "id": "A",
                "text": "You should make use of the Split Data module.",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "You should make use of the Group Categorical Values module.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "You should make use of the Clip Values module.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "You should make use of the Group Data into Bins module.",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: D.\nCommunity:\n100% for A\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_91cbb8a0bab14755a6f320e2fcf83a8f",
        "type": "multiple_choice_single_answer",
        "question": "A set of CSV files contains sales records. All the CSV files have the same data schema.\n\nEach CSV file contains the sales record for a particular month and has the filename sales.csv. Each file is stored in a folder that indicates the month and year when the data was recorded. The folders are in an Azure blob container for which a datastore has been defined in an Azure\n\nMachine Learning workspace. The folders are organized in a parent folder named sales to create the following hierarchical structure:\n\n/sales\n/01-2019\n/sales.csv\n/02-2019\n/sales.csv\n/03-2019\n/sales.csv\n\n\nAt the end of each month, a new folder with that month's sales file is added to the sales folder.\n\nYou plan to use the sales data to train a machine learning model based on the following requirements:\n\n\u2711 You must define a dataset that loads all of the sales data to date into a structure that can be easily converted to a dataframe.\n\n\u2711 You must be able to create experiments that use only data that was created before a specific previous month, ignoring any data that was added\n\nafter that month.\n\n\u2711 You must register the minimum number of datasets possible.\n\nYou need to register the sales data as a dataset in Azure Machine Learning service workspace.\n\nWhat should you do?",
        "options": [
            {
                "id": "A",
                "text": "Create a tabular dataset that references the datastore and explicitly specifies each 'sales/mm-yyyy/sales.csv' file every month. Register the dataset with the name sales_dataset each month, replacing the existing dataset and specifying a tag named month indicating the month and year it was registered. Use this dataset for all experiments.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Create a tabular dataset that references the datastore and specifies the path 'sales/*/sales.csv', register the dataset with the name sales_dataset and a tag named month indicating the month and year it was registered, and use this dataset for all experiments.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Create a new tabular dataset that references the datastore and explicitly specifies each 'sales/mm-yyyy/sales.csv' file every month.\n\nRegister the dataset with the name sales_dataset_MM-YYYY each month with appropriate MM and YYYY values for the month and year. Use the appropriate month-specific dataset for experiments.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Create a tabular dataset that references the datastore and explicitly specifies each 'sales/mm-yyyy/sales.csv' file. Register the dataset with the name sales_dataset each month as a new version and with a tag named month indicating the month and year it was registered. Use this dataset for all experiments, identifying the version to be used based on the month tag as necessary.",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: B.\nCommunity:\n100% for D\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_631594bcf1e54f13a057e84da4d87ffa",
        "type": "multiple_choice_single_answer",
        "question": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\n\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nYou use Azure Machine Learning designer to load the following datasets into an experiment:\n\nDataset1 \n\n\nDataset2 \n\n\nYou need to create a dataset that has the same columns and header row as the input datasets and contains all rows from both input datasets.\n\nSolution: Use the Apply Transformation module.\n\nDoes the solution meet the goal?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: B.\nCommunity:\n100% for A\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_3a6a31a385684a1788e8b984a85ceb37",
        "type": "multiple_choice_multiple_answer",
        "question": "You use the Two-Class Neural Network module in Azure Machine Learning Studio to build a binary classification model. You use the Tune Model\n\nHyperparameters module to tune accuracy for the model.\n\nYou need to configure the Tune Model Hyperparameters module.\n\nWhich two values should you use? Each correct answer presents part of the solution.\n\nNOTE: Each correct selection is worth one point.",
        "options": [
            {
                "id": "A",
                "text": "Number of hidden nodes",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Learning Rate",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "The type of the normalizer",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Number of learning iterations",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "E",
                "text": "Hidden layer specification",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: DE.\nCommunity:\n80% for BD\n20% for DE\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_09d5bc2621724967b60c968e755e721c",
        "type": "multiple_choice_multiple_answer",
        "question": "You create an Azure Machine Learning compute resource to train models. The compute resource is configured as follows:\n\n\u2711 Minimum nodes: 2\n\n\u2711 Maximum nodes: 4\n\nYou must decrease the minimum number of nodes and increase the maximum number of nodes to the following values:\n\n\u2711 Minimum nodes: 0\n\n\u2711 Maximum nodes: 8\n\nYou need to reconfigure the compute resource.\n\nWhat are three possible ways to achieve this goal? Each correct answer presents a complete solution.\n\nNOTE: Each correct selection is worth one point.",
        "options": [
            {
                "id": "A",
                "text": "Use the Azure Machine Learning studio.",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Run the update method of the AmlCompute class in the Python SDK.",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Use the Azure portal.",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Use the Azure Machine Learning designer.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "E",
                "text": "Run the refresh_state() method of the BatchCompute class in the Python SDK.",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_7a014f4c87064ed1bf1acb4e422117a3",
        "type": "multiple_choice_single_answer",
        "question": "You are authoring a notebook in Azure Machine Learning studio.\n\nYou must install packages from the notebook into the currently running kernel. The installation must be limited to the currently running kernel only.\n\nYou need to install the packages.\n\nWhich magic function should you use?",
        "options": [
            {
                "id": "A",
                "text": "!pip",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "%pip",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "!conda",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "%load",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_5bae511856a84d258504528ad5073c20",
        "type": "multiple_choice_single_answer",
        "question": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\n\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nYou are analyzing a numerical dataset which contains missing values in several columns.\n\nYou must clean the missing values using an appropriate operation without affecting the dimensionality of the feature set.\n\nYou need to analyze a full dataset to include all values.\n\nSolution: Use the Last Observation Carried Forward (LOCF) method to impute the missing data points.\n\nDoes the solution meet the goal?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_148e11b92cef4ce8908c1c074898a2ad",
        "type": "multiple_choice_single_answer",
        "question": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\n\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nYou are a data scientist using Azure Machine Learning Studio.\n\nYou need to normalize values to produce an output column into bins to predict a target column.\n\nSolution: Apply a Quantiles binning mode with a PQuantile normalization.\n\nDoes the solution meet the goal?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: B.\nCommunity:\n88% for A\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_81092807b6e24b6fb23245ed1d11fd67",
        "type": "multiple_choice_single_answer",
        "question": "This question is included in a number of questions that depicts the identical set-up. However, every question has a distinctive result. Establish if the recommendation satisfies the requirements.\n\nYou have been tasked with evaluating your model on a partial data sample via k-fold cross-validation.\n\nYou have already configured a k parameter as the number of splits. You now have to configure the k parameter for the cross-validation with the usual value choice.\n\nRecommendation: You configure the use of the value k=10.\n\nWill the requirements be satisfied?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_55d677eed23b47b8b4cee311b0d2ac48",
        "type": "multiple_choice_multiple_answer",
        "question": "You develop a machine learning project on a local machine. The project uses the Azure Machine Learning SDK for Python. You use Git as version control for scripts.\n\nYou submit a training run that returns a Run object.\n\nYou need to retrieve the active Git branch for the training run.\n\nWhich two code segments should you use? Each correct answer presents part of the solution.\n\nNOTE: Each correct selection is worth one point.",
        "options": [
            {
                "id": "A",
                "text": "details = run.get_environment()",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "details.properties['azureml.git.branch']",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "details.properties['azureml.git.commit']",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "details = run.get_details()",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: BC.\nCommunity:\n100% for BD\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_3f06fd2e67594220a757201c9e79a3f2",
        "type": "multiple_choice_single_answer",
        "question": "You are creating a machine learning model. You have a dataset that contains null rows.\n\nYou need to use the Clean Missing Data module in Azure Machine Learning Studio to identify and resolve the null and missing data in the dataset.\n\nWhich parameter should you use?",
        "options": [
            {
                "id": "A",
                "text": "Replace with mean",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Remove entire column",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Remove entire row",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Hot Deck",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "E",
                "text": "Custom substitution value",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "F",
                "text": "Replace with mode",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: C.\nCommunity:\n100% for (100%)\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_f1620913ace846038a394dec75fd4799",
        "type": "multiple_choice_single_answer",
        "question": "You are performing feature engineering on a dataset.\n\nYou must add a feature named CityName and populate the column value with the text London.\n\nYou need to add the new feature to the dataset.\n\nWhich Azure Machine Learning Studio module should you use?",
        "options": [
            {
                "id": "A",
                "text": "Edit Metadata",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Filter Based Feature Selection",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Execute Python Script",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Latent Dirichlet Allocation",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: A.\nCommunity:\n62% for C\n38% for A\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_bc612ccec5be4235901f018e817b39ef",
        "type": "multiple_choice_single_answer",
        "question": "You have an Azure Machine Learning workspace. You are connecting an Azure Data Lake Storage Gen2 account to the workspace as a data store.\n\nYou need to authorize access from the workspace to the Azure Data Lake Storage Gen2 account.\n\nWhat should you use?",
        "options": [
            {
                "id": "A",
                "text": "Service principal",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "SAS token",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Managed identity",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Account key",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: C.\nCommunity:\n100% for A\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_950ee73198a94f20afaecc34e7bb6689",
        "type": "multiple_choice_multiple_answer",
        "question": "You are a data scientist building a deep convolutional neural network (CNN) for image classification.\n\nThe CNN model you build shows signs of overfitting.\n\nYou need to reduce overfitting and converge the model to an optimal fit.\n\nWhich two actions should you perform? Each correct answer presents a complete solution.\n\nNOTE: Each correct selection is worth one point.",
        "options": [
            {
                "id": "A",
                "text": "Add an additional dense layer with 512 input units.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Add L1/L2 regularization.",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Use training data augmentation.",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Reduce the amount of training data.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "E",
                "text": "Add an additional dense layer with 64 input units.",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: BD.\nCommunity:\n100% for BC\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_247f0e4af5d343b8b54ef4844d5e94d8",
        "type": "multiple_choice_single_answer",
        "question": "You create a multi-class image classification deep learning model.\n\nYou train the model by using PyTorch version 1.2.\n\nYou need to ensure that the correct version of PyTorch can be identified for the inferencing environment when the model is deployed.\n\nWhat should you do?",
        "options": [
            {
                "id": "A",
                "text": "Save the model locally as a.pt file, and deploy the model as a local web service.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Deploy the model on computer that is configured to use the default Azure Machine Learning conda environment.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Register the model with a .pt file extension and the default version property.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Register the model, specifying the model_framework and model_framework_version properties.",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_ce5027f1ad1f4ef1bbd3fb975e2d9f19",
        "type": "multiple_choice_multiple_answer",
        "question": "You are training machine learning models in Azure Machine Learning. You use Hyperdrive to tune the hyperparameters.\n\nIn previous model training and tuning runs, many models showed similar performance.\n\nYou need to select an early termination policy that meets the following requirements:\n\n\u2711 accounts for the performance of all previous runs when evaluating the current run avoids comparing the current run with only the best performing run to date\n\nWhich two early termination policies should you use? Each correct answer presents part of the solution.\n\nNOTE: Each correct selection is worth one point.",
        "options": [
            {
                "id": "A",
                "text": "Median stopping",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Bandit",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Default",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Truncation selection",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: AC.\nCommunity:\n100% for AD\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_c0385096823b4935883bd1efe768ae18",
        "type": "multiple_choice_single_answer",
        "question": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\n\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nYou create an Azure Machine Learning service datastore in a workspace. The datastore contains the following files:\n\n\u2711 /data/2018/Q1.csv\n\n\u2711 /data/2018/Q2.csv\n\n\u2711 /data/2018/Q3.csv\n\n\u2711 /data/2018/Q4.csv\n\n\u2711 /data/2019/Q1.csv\n\nAll files store data in the following format:\n\nid,f1,f2,I\n\n1,1,2,0\n\n2,1,1,1\n\n3,2,1,0\n\n4,2,2,1\n\nYou run the following code:\n\ndata_store = Datastore.register_azure_blob_container (workspace=ws,\ndatastore_name= 'data_store\u2019,\ncontainer_name= 'quarterly data\u2019,\naccount_name='companydata\u2019,\naccount_key=\u2019 NRPxk8duxbM3...\u2019\ncreate_if_not_exists=False)\n\n\nYou need to create a dataset named training_data and load the data from all files into a single data frame by using the following code:\n\nSolution: Run the following code:\n\nDoes the solution meet the goal?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: B.\nCommunity:\n91% for A(91%)\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_94e7b68c91a440bd8e04f66d379a7de1",
        "type": "multiple_choice_single_answer",
        "question": "You use the Azure Machine Learning Python SDK to define a pipeline to train a model.\n\nThe data used to train the model is read from a folder in a datastore.\n\nYou need to ensure the pipeline runs automatically whenever the data in the folder changes.\n\nWhat should you do?",
        "options": [
            {
                "id": "A",
                "text": "Set the regenerate_outputs property of the pipeline to True",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Create a ScheduleRecurrance object with a Frequency of auto. Use the object to create a Schedule for the pipeline",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Create a PipelineParameter with a default value that references the location where the training data is stored",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Create a Schedule for the pipeline. Specify the datastore in the datastore property, and the folder containing the training data in the path_on_datastore property",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_3751e809be894fe7a745f207e35eeaae",
        "type": "multiple_choice_single_answer",
        "question": "This question is included in a number of questions that depicts the identical set-up. However, every question has a distinctive result. Establish if the recommendation satisfies the requirements.\n\nYou have been tasked with evaluating your model on a partial data sample via k-fold cross-validation.\n\nYou have already configured a k parameter as the number of splits. You now have to configure the k parameter for the cross-validation with the usual value choice.\n\nRecommendation: You configure the use of the value k=3.\n\nWill the requirements be satisfied?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_af6ed30699f043348dadd182a353a52e",
        "type": "multiple_choice_single_answer",
        "question": "You have been tasked with creating a new Azure pipeline via the Machine Learning designer.\n\nYou have to makes sure that the pipeline trains a model using data in a comma-separated values (CSV) file that is published on a website. A\n\ndataset for the file for this file does not exist.\n\nData from the CSV file must be ingested into the designer pipeline with the least amount of administrative effort as possible.\n\nWhich of the following actions should you take?",
        "options": [
            {
                "id": "A",
                "text": "You should make use of the Convert to TXT module.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "You should add the Copy Data object to the pipeline.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "You should add the Import Data object to the pipeline.",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "You should add the Dataset object to the pipeline.",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: D.\nCommunity:\n100% for C(100%)\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_c3d8963d316b4d32b7d9445e3bab389c",
        "type": "multiple_choice_single_answer",
        "question": "You run an experiment that uses an AutoMLConfig class to define an automated machine learning task with a maximum of ten model training iterations. The task will attempt to find the best performing model based on a metric named accuracy.\n\nYou submit the experiment with the following code:\n\nfrom azureml.core.experiment import Experiment\nautoml_experiment = Experiment (ws, \u2018automl_experiment\u2019)\nautoml_run = automl_experiment.submit (automl_config, show_output=True)\n\n\nYou need to create Python code that returns the best model that is generated by the automated machine learning task.\n\nWhich code segment should you use?",
        "options": [
            {
                "id": "A",
                "text": "best_model = automl_run.get_details()",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "best_model = automl_run.get_metrics()",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "best_model = automl_run.get_file_names()[1]",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "best_model = automl_run.get_output()[1]",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_209c8c1642044cf2801fb583a2cb9a36",
        "type": "multiple_choice_single_answer",
        "question": "Note: This question is part of a series of questions that present the same scenario. Each question in the series contains a unique solution that might meet the stated goals. Some question sets might have more than one correct solution, while others might not have a correct solution.\n\nAfter you answer a question in this section, you will NOT be able to return to it. As a result, these questions will not appear in the review screen.\n\nYou create an Azure Machine Learning pipeline named pipeline1 with two steps that contain Python scripts. Data processed by the first step is passed to the second step.\n\nYou must update the content of the downstream data source of pipeline1 and run the pipeline again.\n\nYou need to ensure the new run of pipeline1 fully processes the updated content.\n\nSolution: Set the allow_reuse parameter of the PythonScriptStep object of both steps to False.\n\nDoes the solution meet the goal?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: B.\nCommunity:\n100% for A\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_072a49ff403a4a288a3ba9b55aac23da",
        "type": "multiple_choice_single_answer",
        "question": "You manage an Azure Machine Learning workspace. You have an environment for training jobs which uses an existing Docker image.\n\nA new version of the Docker image is available.\n\nYou need to use the latest version of the Docker image for the environment configuration by using the Azure Machine Learning SDK v2.\n\nWhat should you do?",
        "options": [
            {
                "id": "A",
                "text": "Modify the conda_file to specify the new version of the Docker image.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Use the Environment class to create a new version of the environment.",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Use the create_or_update method to change the tag of the image.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Change the description parameter of the environment configuration.",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: A.\nCommunity:\n90% for B\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_590df2b4ba9248718bc5a1fffdaacbca",
        "type": "multiple_choice_single_answer",
        "question": "You plan to deliver a hands-on workshop to several students. The workshop will focus on creating data visualizations using Python. Each student will use a device that has internet access.\n\nStudent devices are not configured for Python development. Students do not have administrator access to install software on their devices. Azure subscriptions are not available for students.\n\nYou need to ensure that students can run Python-based data visualization code.\n\nWhich Azure tool should you use?",
        "options": [
            {
                "id": "A",
                "text": "Anaconda Data Science Platform",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Azure BatchAI",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Azure Notebooks",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Azure Machine Learning Service",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_c011e0b5190a49babc317676f634e7ed",
        "type": "multiple_choice_multiple_answer",
        "question": "You plan to use the Hyperdrive feature of Azure Machine Learning to determine the optimal hyperparameter values when training a model.\n\nYou must use Hyperdrive to try combinations of the following hyperparameter values:\n\n\u2711 learning_rate: any value between 0.001 and 0.1\n\n\u2711 batch_size: 16, 32, or 64\n\nYou need to configure the search space for the Hyperdrive experiment.\n\nWhich two parameter expressions should you use? Each correct answer presents part of the solution.\n\nNOTE: Each correct selection is worth one point.",
        "options": [
            {
                "id": "A",
                "text": "a choice expression for learning_rate",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "a uniform expression for learning_rate",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "a normal expression for batch_size",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "a choice expression for batch_size",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "E",
                "text": "a uniform expression for batch_size",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_2e099b9351724c99ae724bfb7c062d93",
        "type": "multiple_choice_multiple_answer",
        "question": "You are building a binary classification model by using a supplied training set.\n\nThe training set is imbalanced between two classes.\n\nYou need to resolve the data imbalance.\n\nWhat are three possible ways to achieve this goal? Each correct answer presents a complete solution.\n\nNOTE: Each correct selection is worth one point.",
        "options": [
            {
                "id": "A",
                "text": "Penalize the classification",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Resample the dataset using undersampling or oversampling",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Normalize the training feature set",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Generate synthetic samples in the minority class",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "E",
                "text": "Use accuracy as the evaluation metric of the model",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_0808afbcf14940bf83cd4a23d2ac45be",
        "type": "multiple_choice_multiple_answer",
        "question": "You are analyzing a dataset containing historical data from a local taxi company. You are developing a regression model.\n\nYou must predict the fare of a taxi trip.\n\nYou need to select performance metrics to correctly evaluate the regression model.\n\nWhich two metrics can you use? Each correct answer presents a complete solution?\n\nNOTE: Each correct selection is worth one point.",
        "options": [
            {
                "id": "A",
                "text": "a Root Mean Square Error value that is low",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "an R-Squared value close to 0",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "an F1 score that is low",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "an R-Squared value close to 1",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "E",
                "text": "an F1 score that is high",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "F",
                "text": "a Root Mean Square Error value that is high",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_90ffbe5735604cd1b50d1a4756659d2a",
        "type": "multiple_choice_single_answer",
        "question": "You are implementing a machine learning model to predict stock prices.\n\nThe model uses a PostgreSQL database and requires GPU processing.\n\nYou need to create a virtual machine that is pre-configured with the required tools.\n\nWhat should you do?",
        "options": [
            {
                "id": "A",
                "text": "Create a Data Science Virtual Machine (DSVM) Windows edition.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Create a Geo Al Data Science Virtual Machine (Geo-DSVM) Windows edition.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Create a Deep Learning Virtual Machine (DLVM) Linux edition.",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Create a Deep Learning Virtual Machine (DLVM) Windows edition.",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: A.\nCommunity:\n100% for C\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_8c243e10d68741189ef573d43822d3c8",
        "type": "multiple_choice_single_answer",
        "question": "You are in the process of constructing a deep convolutional neural network (CNN). The CNN will be used for image classification.\n\nYou notice that the CNN model you constructed displays hints of overfitting.\n\nYou want to make sure that overfitting is minimized, and that the model is converged to an optimal fit.\n\nWhich of the following is TRUE with regards to achieving your goal?",
        "options": [
            {
                "id": "A",
                "text": "You have to add an additional dense layer with 512 input units, and reduce the amount of training data.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "You have to add L1/L2 regularization, and reduce the amount of training data.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "You have to reduce the amount of training data and make use of training data augmentation.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "You have to add L1/L2 regularization, and make use of training data augmentation.",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "E",
                "text": "You have to add an additional dense layer with 512 input units, and add L1/L2 regularization.",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: B.\nCommunity:\n100% for D\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_c5a310ccd9b4420792a63348ea278261",
        "type": "multiple_choice_multiple_answer",
        "question": "You use the following code to define the steps for a pipeline: from azureml.core import Workspace, Experiment, Run from azureml.pipeline.core\n\nimport Pipeline from azureml.pipeline.steps import PythonScriptStep ws = Workspace.from_config()\n\n. . .\n\nstep1 = PythonScriptStep(name=\"step1\", ...)\n\nstep2 = PythonScriptsStep(name=\"step2\", ...)\n\npipeline_steps = [step1, step2]\n\nYou need to add code to run the steps.\n\nWhich two code segments can you use to achieve this goal? Each correct answer presents a complete solution.\n\nNOTE: Each correct selection is worth one point.",
        "options": [
            {
                "id": "A",
                "text": "experiment = Experiment(workspace=ws, name='pipeline-experiment') run = experiment.submit(config=pipeline_steps)",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "run = Run(pipeline_steps)",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "pipeline = Pipeline(workspace=ws, steps=pipeline_steps) experiment = Experiment(workspace=ws, name='pipeline-experiment') run =\n\nexperiment.submit(pipeline)",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "pipeline = Pipeline(workspace=ws, steps=pipeline_steps) run = pipeline.submit(experiment_name='pipeline-experiment')",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_ffd097f01d3c45aeb34c97f097af207d",
        "type": "multiple_choice_multiple_answer",
        "question": "You plan to run a Python script as an Azure Machine Learning experiment.\n\nThe script must read files from a hierarchy of folders. The files will be passed to the script as a dataset argument.\n\nYou must specify an appropriate mode for the dataset argument.\n\nWhich two modes can you use? Each correct answer presents a complete solution.\n\nNOTE: Each correct selection is worth one point.",
        "options": [
            {
                "id": "A",
                "text": "to_pandas_dataframe()",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "as_download()",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "as_upload()",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "as_mount()",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "Exam topics say B only (despite select 2), community says BD.",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_650c0648c428434c8489af438eeeb753",
        "type": "multiple_choice_single_answer",
        "question": "You deploy a real-time inference service for a trained model.\n\nThe deployed model supports a business-critical application, and it is important to be able to monitor the data submitted to the web service and the predictions the data generates.\n\nYou need to implement a monitoring solution for the deployed model using minimal administrative effort.\n\nWhat should you do?",
        "options": [
            {
                "id": "A",
                "text": "View the explanations for the registered model in Azure ML studio.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Enable Azure Application Insights for the service endpoint and view logged data in the Azure portal.",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "View the log files generated by the experiment used to train the model.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Create an ML Flow tracking URI that references the endpoint, and view the data logged by ML Flow.",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_0f00d238c9f7429b84fb6a3560af5ad0",
        "type": "multiple_choice_single_answer",
        "question": "You create a binary classification model. You use the Fairlearn package to assess model fairness.\n\nYou must eliminate the need to retrain the model.\n\nYou need to implement the Fairlearn package.\n\nWhich algorithm should you use?",
        "options": [
            {
                "id": "A",
                "text": "fairlearn.reductions.ExponentiatedGradient",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "fairlearn.postprocessing.ThresholdOptimizer",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "fairlearnpreprocessing.CorrelationRemover",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "fairlearn.reductions.GridSearch",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: C.\nCommunity:\n100% for B\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_4fa004c864e74c2babd29976641de939",
        "type": "multiple_choice_single_answer",
        "question": "You train a model and register it in your Azure Machine Learning workspace. You are ready to deploy the model as a real-time web service.\n\nYou deploy the model to an Azure Kubernetes Service (AKS) inference cluster, but the deployment fails because an error occurs when the service runs the entry script that is associated with the model deployment.\n\nYou need to debug the error by iteratively modifying the code and reloading the service, without requiring a re-deployment of the service for each code update.\n\nWhat should you do?",
        "options": [
            {
                "id": "A",
                "text": "Modify the AKS service deployment configuration to enable application insights and re-deploy to AKS.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Create an Azure Container Instances (ACI) web service deployment configuration and deploy the model on ACI.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Add a breakpoint to the first line of the entry script and redeploy the service to AKS.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Create a local web service deployment configuration and deploy the model to a local Docker container.",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "E",
                "text": "Register a new version of the model and update the entry script to load the new version of the model from its registered path.",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: B.\nCommunity:\n100% for D\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_78d9ea2b421d4d11892afecb9a120ab8",
        "type": "multiple_choice_multiple_answer",
        "question": "You are developing a hands-on workshop to introduce Docker for Windows to attendees.\n\nYou need to ensure that workshop attendees can install Docker on their devices.\n\nWhich two prerequisite components should attendees install on the devices? Each correct answer presents part of the solution.\n\nNOTE: Each correct selection is worth one point.",
        "options": [
            {
                "id": "A",
                "text": "Microsoft Hardware-Assisted Virtualization Detection Tool",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Kitematic",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "BIOS-enabled virtualization",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "VirtualBox",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "E",
                "text": "Windows 10 64-bit Professional",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_56a5218fd50342fcbb075473a6f6cf24",
        "type": "multiple_choice_multiple_answer",
        "question": "You create a pipeline in designer to train a model that predicts automobile prices.\n\nBecause of non-linear relationships in the data, the pipeline calculates the natural log (Ln) of the prices in the training data, trains a model to predict this natural log of price value, and then calculates the exponential of the scored label to get the predicted price.\n\nThe training pipeline is shown in the exhibit. (Click the Training pipeline tab.)\n\nTraining pipeline \n\u00a9 Automobile data |\n\niS\n\n\u00a9 Apply Math Operation Qo |\n\nReplace price with Lniprice)\n\n|\n\n70% train / 30% validate\n\n\u00a9 Linear Regression ry | E Split Data al\n\n= fan\n\n| (fe Train Model i) |\n\nPredict Ln(price)\n\n{Score Model Qo\nGet Ln(price) prediction\n\nJ\n\n\u00a9 Apply Math Operation Qo\nReplace Scored Labels w. Exp(Scored Labels)\n\nCC\n\n& ApplySQLTransformation @\nSELECT [Scored Labels] AS predicted_price\n\n\n\nYou create a real-time inference pipeline from the training pipeline, as shown in the exhibit. (Click the Real-time pipeline tab.)\n\nReal-time pipeline \n\u00a9 Automobile data\n\n| Apply Math Operation\nReplace price with Ln(price)\n\n( \u00a9 MD-Automobile_Price_Regress... ]\n\n\u2014 an,\n\nGet Ln(price) prediction\n\n[i Score Model |\n\n\u00a9 Apply Math Operation\nReplace Scored Labels w. Exp(Scored Labels)\n\n\u2014J\n\n[ Apply SQL Transformation |\n\nSELECT [Scored Labels] AS predicted_price\n\n\n\nYou need to modify the inference pipeline to ensure that the web service returns the exponential of the scored label as the predicted automobile price and that client applications are not required to include a price value in the input values.\n\nWhich three modifications must you make to the inference pipeline? Each correct answer presents part of the solution.\n\nNOTE: Each correct selection is worth one point.",
        "options": [
            {
                "id": "A",
                "text": "Connect the output of the Apply SQL Transformation to the Web Service Output module.",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Replace the Web Service Input module with a data input that does not include the price column.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Add a Select Columns module before the Score Model module to select all columns other than price.",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Replace the training dataset module with a data input that does not include the price column.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "E",
                "text": "Remove the Apply Math Operation module that replaces price with its natural log from the data fiow.",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "F",
                "text": "Remove the Apply SQL Transformation module from the data fiow.",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_c50568bd1b6e403cb2c611f7e378bd82",
        "type": "multiple_choice_single_answer",
        "question": "You plan to use a Data Science Virtual Machine (DSVM) with the open source deep learning frameworks Caffe2 and PyTorch.\n\nYou need to select a pre-configured DSVM to support the frameworks.\n\nWhat should you create?",
        "options": [
            {
                "id": "A",
                "text": "Data Science Virtual Machine for Windows 2012",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Data Science Virtual Machine for Linux (CentOS)",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Geo AI Data Science Virtual Machine with ArcGIS",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Data Science Virtual Machine for Windows 2016",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "E",
                "text": "Data Science Virtual Machine for Linux (Ubuntu)",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_ffcca60419154e0bb8ad6d9db697bd1c",
        "type": "multiple_choice_single_answer",
        "question": "You plan to use a Deep Learning Virtual Machine (DLVM) to train deep learning models using Compute Unified Device Architecture (CUDA)\n\ncomputations.\n\nYou need to configure the DLVM to support CUD",
        "options": [
            {
                "id": "A",
                "text": "Solid State Drives (SSD)",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Computer Processing Unit (CPU) speed increase by using overclocking",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Graphic Processing Unit (GPU)",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "High Random Access Memory (RAM) configuration",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "E",
                "text": "Intel Software Guard Extensions (Intel SGX) technology",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_3e7c998f93d348e8baeb3b25b21b1bc3",
        "type": "multiple_choice_single_answer",
        "question": "You have a comma-separated values (CSV) file containing data from which you want to train a classification model.\n\nYou are using the Automated Machine Learning interface in Azure Machine Learning studio to train the classification model. You set the task type to Classification.\n\nYou need to ensure that the Automated Machine Learning process evaluates only linear models.\n\nWhat should you do?",
        "options": [
            {
                "id": "A",
                "text": "Add all algorithms other than linear ones to the blocked algorithms list.",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Set the Exit criterion option to a metric score threshold.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Clear the option to perform automatic featurization.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Clear the option to enable deep learning.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "E",
                "text": "Set the task type to Regression.",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: C.\nCommunity:\n100% for A\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_406717f3973e49f1812d6313aa3d22a4",
        "type": "multiple_choice_single_answer",
        "question": "This question is included in a number of questions that depicts the identical set-up. However, every question has a distinctive result. Establish if the recommendation satisfies the requirements.\n\nYou are in the process of carrying out feature engineering on a dataset.\n\nYou want to add a feature to the dataset and fill the column value.\n\nRecommendation: You must make use of the Join Data Azure Machine Learning Studio module.\n\nWill the requirements be satisfied?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_3e59267b760945fa9c0897c0e5cdc6eb",
        "type": "multiple_choice_multiple_answer",
        "question": "You are building a regression model for estimating the number of calls during an event.\n\nYou need to determine whether the feature values achieve the conditions to build a Poisson regression model.\n\nWhich two conditions must the feature set contain? Each correct answer presents part of the solution.\n\nNOTE: Each correct selection is worth one point.",
        "options": [
            {
                "id": "A",
                "text": "The label data must be a negative value.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "The label data must be whole numbers.",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "The label data must be non-discrete.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "The label data must be a positive value.",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "E",
                "text": "The label data can be positive or negative.",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_43e29f8bc7ac41a789ef61542f28160a",
        "type": "multiple_choice_single_answer",
        "question": "This question is included in a number of questions that depicts the identical set-up. However, every question has a distinctive result. Establish if the recommendation satisfies the requirements.\n\nYou are planning to make use of Azure Machine Learning designer to train models.\n\nYou need choose a suitable compute type.\n\nRecommendation: You choose Attached compute.\n\nWill the requirements be satisfied?",
        "options": [
            {
                "id": "A",
                "text": "Yes",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "No",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_39f380e58d8349aaa2ba1474a7f7a717",
        "type": "multiple_choice_single_answer",
        "question": "You plan to run a Python script as an Azure Machine Learning experiment.\n\nThe script contains the following code:\n\nimport os, argparse, glob\nfrom azureml.core import Run\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--input-data', type=str, dest='data_folder')\nargs = parser.parse_args()\n\ndata_path = args.data_folder\n\nfile_paths = glob.glob(data_path + \"/*.jpg\")\n\n\nYou must specify a file dataset as an input to the script. The dataset consists of multiple large image files and must be streamed directly from its source.\n\nYou need to write code to define a ScriptRunConfig object for the experiment and pass the ds dataset as an argument.\n\nWhich code segment should you use?",
        "options": [
            {
                "id": "A",
                "text": "arguments = ['--input-data', ds.to_pandas_dataframe()]",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "arguments = ['--input-data', ds.as_mount()]",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "arguments = ['--data-data', ds]",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "arguments = ['--input-data', ds.as_download()]",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: A.\nCommunity:\n100% for B\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_66f6d4936a024b419bbbda295aff9a67",
        "type": "multiple_choice_single_answer",
        "question": "You are preparing to train a regression model via automated machine learning. The data available to you has features with missing values, as well as categorical features with little discrete values.\n\nYou want to make sure that automated machine learning is configured as follows:\n\n\u2711 missing values must be automatically imputed.\n\n\u2711 categorical features must be encoded as part of the training task.\n\nWhich of the following actions should you take?",
        "options": [
            {
                "id": "A",
                "text": "You should make use of the featurization parameter with the 'auto' value pair.",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "You should make use of the featurization parameter with the 'off' value pair.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "You should make use of the featurization parameter with the 'on' value pair.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "You should make use of the featurization parameter with the 'FeaturizationConfig' value pair.",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_ebde33f255e848988cb6e8eba66b7ca2",
        "type": "multiple_choice_multiple_answer",
        "question": "You use the Azure Machine Learning SDK to run a training experiment that trains a classification model and calculates its accuracy metric.\n\nThe model will be retrained each month as new data is available.\n\nYou must register the model for use in a batch inference pipeline.\n\nYou need to register the model and ensure that the models created by subsequent retraining experiments are registered only if their accuracy is higher than the currently registered model.\n\nWhat are two possible ways to achieve this goal? Each correct answer presents a complete solution.\n\nNOTE: Each correct selection is worth one point.",
        "options": [
            {
                "id": "A",
                "text": "Specify a different name for the model each time you register it.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Register the model with the same name each time regardless of accuracy, and always use the latest version of the model in the batch inferencing pipeline.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Specify the model framework version when registering the model, and only register subsequent models if this value is higher.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Specify a property named accuracy with the accuracy metric as a value when registering the model, and only register subsequent models if their accuracy is higher than the accuracy property value of the currently registered model.",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "E",
                "text": "Specify a tag named accuracy with the accuracy metric as a value when registering the model, and only register subsequent models if their accuracy is higher than the accuracy tag value of the currently registered model.",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: CE.\nCommunity:\n100% for DE\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_e9896efaf76145a3bd75b293fbe06667",
        "type": "multiple_choice_single_answer",
        "question": "You are a data scientist working for a hotel booking website company. You use the Azure Machine Learning service to train a model that identifies fraudulent transactions.\n\nYou must deploy the model as an Azure Machine Learning real-time web service using the Model.deploy method in the Azure Machine Learning\n\nSDK. The deployed web service must return real-time predictions of fraud based on transaction data input.\n\nYou need to create the script that is specified as the entry_script parameter for the InferenceConfig class used to deploy the model.\n\nWhat should the entry script do?",
        "options": [
            {
                "id": "A",
                "text": "Register the model with appropriate tags and properties.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "B",
                "text": "Create a Conda environment for the web service compute and install the necessary Python packages.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "C",
                "text": "Load the model and use it to predict labels from input data.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "D",
                "text": "Start a node on the inference cluster where the web service is deployed.",
                "is_correct": false,
                "explanation": ""
            },
            {
                "id": "E",
                "text": "Specify the number of cores and the amount of memory required for the inference compute.",
                "is_correct": false,
                "explanation": ""
            }
        ],
        "feedback": "ExamTopics answer: C.\nCommunity:\n100% for (100%)\n",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_3bf4f169748448008bae22dfa5f1f357",
        "type": "multiple_choice_single_answer",
        "question": "(hotspot) Fill in the blank.\nTo move a large dataset from Azure Machine Learning Studio to a Weka environment, the data must be converted to ______ format.",
        "options": [
            {"id": "A", "text": "CSV", "is_correct": false, "explanation": ""},
            {"id": "B", "text": "DOCX", "is_correct": false, "explanation": ""},
            {"id": "C", "text": "ARFF", "is_correct": true, "explanation": "Use the Convert to ARFF module in Azure Machine Learning Studio to convert datasets and results in Azure Machine Learning to the attribute relation file format used by the Weka toolset. This format is known as ARFF.\n\nThe ARFF data specification for Weka supports multiple machine learning tasks, including data preprocessing, classification, and feature selection. In this format, data is organized by entities and their attributes, and is contained in a single text file."},
            {"id": "D", "text": "TXT", "is_correct": false, "explanation": ""}
        ],
        "feedback": "Probably irrelevant. https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/convert-to-arff",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_be245ce466fe4811a39d819f31e69416",
        "type": "multiple_choice_multiple_answer",
        "question": "(drag and drop) You are in the process of constructing a regression model.\nYou would like to make it a Poisson regression model. To achieve your goal, the feature values need to meet certain conditions.Which of the following are relevant conditions with regards to the label data?",
        "options": [
            {"id": "A", "text": "It must be whole numbers", "is_correct": true, "explanation": ""},
            {"id": "B", "text": "It must be a negative value", "is_correct": false, "explanation": ""},
            {"id": "C", "text": "It must be fractions", "is_correct": false, "explanation": ""},
            {"id": "D", "text": "It must be non-discrete", "is_correct": false, "explanation": ""},
            {"id": "E", "text": "It must be a positive value", "is_correct": true, "explanation": ""}
        ],
        "feedback": "Poisson regression is intended for use in regression models that are used to predict numeric values, typically counts. Therefore, you should use this module to create your regression models only if the values you are trying to predict fit the following conditions:\n\nThe response variable has a Poisson distribution, Counts cannot be negative. A Poisson distribution is a discrete distribution, therefore it is not meaningful to use this mehtod with non-integer numbers.\n\nReference:\n\nhttps://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/poisson-regression",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_b887da7a7772462e9ee4f3dcf7986c77",
        "type": "multiple_choice_multiple_answer",
        "question": "(drag and drop) You have been tasked with evaluating the performance of a binary classification model that you created.\nYou need to choose evaluation metrics to achieve your goal\n\n Which of the following are the metrics you would choose?",
        "options": [
            {"id": "A", "text": "Relative Absolute Error", "is_correct": false, "explanation": ""},
            {"id": "B", "text": "Accuracy", "is_correct": true, "explanation": ""},
            {"id": "C", "text": "Coefficient of determination", "is_correct": false, "explanation": ""},
            {"id": "D", "text": "Precision", "is_correct": true, "explanation": ""},
            {"id": "E", "text": "Mean absolute error", "is_correct": false, "explanation": ""}
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_6bc0ca779ab94e97b0335cdb81892daf",
        "type": "multiple_choice_multiple_answer",
        "question": "You build a binary classification model using the Azure Machine Learning Studio Two-Class Neural Network module.\nYou are preparing to configure the Tune Model Hyperparameters module for the purpose of tuning accuracy for the model.\n\nWhich of the following are valid parameters for the Two-Class Neural Network module? Answer by dragging the correct options from the list to the answer area",
        "options": [
            {"id": "A", "text": "Depth of the tree", "is_correct": false, "explanation": ""},
            {"id": "B", "text": "Random number seed", "is_correct": true, "explanation": ""},
            {"id": "C", "text": "Optimization tolerance", "is_correct": false, "explanation": ""},
            {"id": "D", "text": "The initial learning wieghts diameters", "is_correct": true, "explanation": ""},
            {"id": "E", "text": "Lambda", "is_correct": false, "explanation": ""},
            {"id": "F", "text": "Number of learning iterations", "is_correct": true, "explanation": ""},
            {"id": "G", "text": "Project to the unit-sphere", "is_correct": false, "explanation": ""}
        ],
        "feedback": "Reference:\n\nhttps://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/two-class-neural-network",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_a4dec7241d654887ae0973772861e0a3",
        "type": "ordering",
        "question": "You create an Azure Machine Learning workspace.\n\nYou must implement dedicated compute for model training in the workspace by using Azure Synapse compute resources. The solution must attach the dedicated compute and start an Azure Synapse session.\n\nYou need to implement the computer resources.\n\nWhich three actions should you perform in sequence?",
        "options": [
            {
                "id": "A",
                "text": "Create compute clusters by using Azure Machine Learning Studio."
            },
            {
                "id": "B",
                "text": "Create a linked service by using Azure Synapse Studio."
            },
            {
                "id": "C",
                "text": "Attach the Compute in Azure Machine Learning Studio."
            },
            {
                "id": "D",
                "text": "Create an Azure Synapse workspace by using the Azure Portal."
            },
            {
                "id": "E",
                "text": "Create an Azure Synapse Compute"
            }
        ],
        "correct_order": [
            "D",
            "E",
            "C"
        ],
        "feedback": "Should be correct. Not really part of any learning path.",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_7896f4ca46514b9b98d7edfe1d75d338",
        "type": "ordering",
        "question": "You are building an intelligent solution using machine learning models.\n\nThe environment must support the following requirements:\n\n* Data scientists must build notebooks in a cloud environment\n* Data scientists must use automatic feature engineering and model building in machine learning pipelines.\n* Notebooks must be deployed to retrain using Spark instances with dynamic worker allocation.\n* Notebooks must be exportable to be version controlled locally.\n\nYou need to create the environment.\n\nWhich four actions should you perform in sequence?",
        "options": [
            {
                "id": "A",
                "text": "Install the Azure Machine Learning SDK for Python on the cluster."
            },
            {
                "id": "B",
                "text": "When the cluster is ready, export Zeppelin notebooks to a local environment"
            },
            {
                "id": "C",
                "text": "Create and execute a Jupyter notebook by using automated machine learning (AutoML) on the cluster."
            },
            {
                "id": "D",
                "text": "Install Microsoft Machine Learning for Apache Spark."
            },
            {
                "id": "E",
                "text": "When the cluster is ready and has processed the notebook, export your Jupyter notebook to a local environment."
            },
            {
                "id": "F",
                "text": "Create an Azure HDInsight cluster to include in Apache Spark MLib library."
            },
            {
                "id": "G",
                "text": "Create and execute the Zeppelin notebooks on the cluster."
            },
            {
                "id": "H",
                "text": "Create an Azure Databricks cluster."
            }
        ],
        "correct_order": [
            "H",
            "A",
            "G",
            "B"
        ],
        "feedback": "Should be correct. Not really part of any learning path.",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_b934b2f66c8444c788989a6f1d4985e8",
        "type": "ordering",
        "question": "You are creating an experiment by using Azure Machine Learning Studio.\n\nYou must divide the data into four subsets for evaluation. There is a high degree of missing values in the data. You must prepare the data for analysis.\n\nYou need to select appropriate methods for producing the experiment.\n\nWhich three modules should you run in sequence? To answer, move the appropriate actions from the list of actions to the answer area and arrange them in the correct order.\n\nNOTE: More than one order of answer choices is correct. You will receive credit for any of the correct orders you select.",
        "options": [
            {
                "id": "A",
                "text": "Build Counting Transform"
            },
            {
                "id": "B",
                "text": "Missing Values Scrubber"
            },
            {
                "id": "C",
                "text": "Feature Hashing"
            },
            {
                "id": "D",
                "text": "Clean Missing Data"
            },
            {
                "id": "E",
                "text": "Replace Discrete Values"
            },
            {
                "id": "F",
                "text": "Import Data"
            },
            {
                "id": "G",
                "text": "Latent Dirichlet Transformation"
            },
            {
                "id": "H",
                "text": "Partition and Sample"
            }
        ],
        "correct_order": [
            "F",
            "D",
            "H"
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_32b4f0d788bc427fa1465b3344dae16a",
        "type": "multiple_choice_multiple_answer",
        "question": "You are retrieving data from a large datastore by using Azure Machine Learning Studio.\n\nYou must create a subset of the data for testing purposes using a random sampling seed based on the system clock.\n\nYou add the Partition and Sample module to your experiment.\n\nYou need to select the properties for the module.\n\nWhich values should you select? To answer, select the appropriate options in the answer area.\n\nNOTE: Each correct selection is worth one point",
        "options": [
            {"id": "A", "text": "(Partition or sample mode) Assign to Folds", "is_correct": false, "explanation": ""},
            {"id": "B", "text": "(Partition or sample mode) Pick Fold", "is_correct": false, "explanation": ""},
            {"id": "C", "text": "(Partition or sample mode) Sampling", "is_correct": true, "explanation": ""},
            {"id": "D", "text": "(Partition or sample mode) Head", "is_correct": false, "explanation": ""},
            {"id": "E", "text": "(Random seed for sampling) 0", "is_correct": true, "explanation": "Default value is 0. It generates the random seed based on the system clock."},
            {"id": "F", "text": "(Random seed for sampling) 1", "is_correct": false, "explanation": ""},
            {"id": "G", "text": "(Random seed for sampling) time.clock()", "is_correct": false, "explanation": ""},
            {"id": "H", "text": "(Random seed for sampling) utcNow()", "is_correct": false, "explanation": ""}
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_b7ab5de6cbaa40c8a4ad547cf4ef7e58",
        "type": "multiple_choice_multiple_answer",
        "question": "The finance team asks you to train a model using data in an Azure Storage blob container named finance-data.\n\nYou need to register the container as a datastore in an Azure Machine Learning workspace and ensure that an error will be raised if the container does not exist.\n\nHow should you complete the code? To answer, select the appropriate options in the answer area\n\n```\ndatstore = Datastore.____(\n\tworkspace=ws,\n\tdatastore_name='finance_datastore',\n\tcontainer_name='finance-data',\n\taccount_name='fintrainingdatastorage',\n\taccount_key='...',\n\t____\n)\n```",
        "options": [
            {"id": "A", "text": "(first) `register_azure_blob_container`", "is_correct": true, "explanation": ""},
            {"id": "B", "text": "(first) `register_azure_file_share`", "is_correct": false, "explanation": ""},
            {"id": "C", "text": "(first) `register_azure_data_lake`", "is_correct": false, "explanation": ""},
            {"id": "D", "text": "(first) `register_azure_sql_database`", "is_correct": false, "explanation": ""},
            {"id": "E", "text": "(second) `create_if_not_exists=True`", "is_correct": false, "explanation": ""},
            {"id": "F", "text": "(second) `create_if_not_exists=False`", "is_correct": true, "explanation": ""},
            {"id": "G", "text": "(second) `overwrite=True`", "is_correct": false, "explanation": ""},
            {"id": "H", "text": "(second) `overwrite=False`", "is_correct": false, "explanation": ""}
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_bd4277d8f900454e8eb5a5a6393d17be",
        "type": "ordering",
        "question": "An organization uses Azure Machine Learning service and wants to expand their use of machine learning.\n\nYou have the following compute environments (name, compute type):\n\n* nb_server, Compute Instance\n* aks_cluster, Azure Kubernetes Service\n* mlc_cluster, Machine Learning Compute\n\nThe organization does not want to create another compute environment. You need to determine which compute environment to use for the following scenarios\n\n1. Run an Azure Machine Learning Designer training pipeline\n2. Deploying a web service from the Azure Machine Learning Designer.\n\nWhich compute types should you use?",
        "options": [
            {
                "id": "A",
                "text": "nb_server"
            },
            {
                "id": "B",
                "text": "aks_cluster"
            },
            {
                "id": "C",
                "text": "mlc_cluster"
            }
        ],
        "correct_order": [
            "C",
            "B"
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_83695f3795174891a8242b26ce78f793",
        "type": "ordering",
        "question": "You are analyzing a raw dataset that requires cleaning.\n\nYou must perform transformations and manipulations by using Azure Machine Learning Studio.\n\nYou need to identify the correct modules to perform the transformations.\n\nWhich modules should you choose? To answer, drag the appropriate modules to the correct scenarios. Each module may be used once, more than once, or not at all.\n\nYou may need to drag the split bar between panes or scroll to view content.\n\nNOTE: Each correct selection is worth one point\n\n1. Replace missing values by removing rows and columns\n2. Increase the number of low-incidence examples in the dataset\n3. Convert a categorical features into a binary indicator\n 4. Remove potential duplicates from a dataset",
        "options": [
            {
                "id": "A",
                "text": "Convert to Indicator Values"
            },
            {
                "id": "B",
                "text": "SMOTE"
            },
            {
                "id": "C",
                "text": "Threshold Filter"
            },
            {
                "id": "D",
                "text": "Clean Missing Data"
            },
            {
                "id": "E",
                "text": "Remove Duplicate Rows"
            }
        ],
        "correct_order": [
            "D",
            "B",
            "A",
            "E"
        ],
        "feedback": "Reference:\n\nhttps://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/smote\n\nhttps://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/convert-to-indicator-value",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_a895f01bbec94649bc3107733235f510",
        "type": "multiple_choice_single_answer",
        "question": "You create an Azure Machine Learning workspace.\n\nYou must create a custom role named DataScientist that meets the following requirements:\n\n* Role members must not be able to delete the workspace.\n* Role members must not be able to create, update, or delete compute resources in the workspace.\n* Role members must not be able to add new users to the workspace.\n\nYou need to create a JSON file for the DataScientist role in the Azure Machine Learning workspace.\n\nThe custom role must enforce the restrictions specified by the IT Operations team.\n\nWhich JSON code segment should you use?",
        "options": [
            {
                "id": "A", 
                "text": "\n```\n{\n  \"Name\": \"DataScientist\",\n  \"IsCustom\": true,\n  \"Actions\": [\"*\"],\n  \"NotActions\": [\n    \"Microsoft.MachineLearningServices/workspaces/*/delete\",\n    \"Microsoft.MachineLearningServices/workspaces/computes/*/write\",\n    \"Microsoft.MachineLearningServices/workspaces/computes/*/delete\",\n    \"Microsoft.Authorization/*/write\"\n  ]\n}\n```",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "B", 
                "text": "\n```\n{\n  \"Name\": \"DataScientist\",\n  \"IsCustom\": true,\n  \"Actions\": [\"*\"],\n  \"NotActions\": []\n}\n```",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "C", 
                "text": "\n```\n{\n  \"Name\": \"DataScientist\",\n  \"IsCustom\": true,\n  \"Actions\": [\n    \"Microsoft.MachineLearningServices/workspaces/*/delete\",\n    \"Microsoft.MachineLearningServices/workspaces/computes/*/write\",\n    \"Microsoft.MachineLearningServices/workspaces/computes/*/delete\",\n    \"Microsoft.Authorization/*/write\"\n  ],\n  \"NotActions\": []\n}\n```",
                "is_correct": true,
                "explanation": ""
            },
            {
                "id": "D", 
                "text": "\n```\n{\n  \"Name\": \"DataScientist\",\n  \"IsCustom\": true,\n  \"Actions\": [],\n  \"NotActions\": [\"*\"]\n}\n```",
                "is_correct": true,
                "explanation": ""
            }
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_a8877b060c7b41f49402bd6c143c872e",
        "type": "multiple_choice_multiple_answer",
        "question": "You are performing a classification task in Azure Machine Learning Studio.\n\nYou must prepare balanced testing and training samples based on a provided data set.\n\nYou need to split the data with a 0.75:0.25 ratio.\n\nWhich value should you use for each parameter? To answer, select the appropriate options in the answer area.\n\nNOTE: Each correct selection is worth one point.\n\n1. Splitting mode\n2. Fraction of rows in the first output dataset\n3. Randomized split\n4. Stratified split",
        "options": [
            {"id": "A", "text": "(1) Split rows", "is_correct": true, "explanation": ""},
            {"id": "B", "text": "(1) Recommender split", "is_correct": false, "explanation": ""},
            {"id": "C", "text": "(1) Regular expression split", "is_correct": false, "explanation": ""},
            {"id": "D", "text": "(1) Relative expression split", "is_correct": false, "explanation": ""},
            {"id": "E", "text": "(2) 0.75", "is_correct": true, "explanation": ""},
            {"id": "F", "text": "(2) 0.25", "is_correct": false, "explanation": ""},
            {"id": "G", "text": "(2) 0.5", "is_correct": false, "explanation": ""},
            {"id": "H", "text": "(2) 1", "is_correct": false, "explanation": ""},
            {"id": "I", "text": "(3) True", "is_correct": true, "explanation": ""},
            {"id": "J", "text": "(3) False", "is_correct": false, "explanation": ""},
            {"id": "K", "text": "(4) True", "is_correct": false, "explanation": ""},
            {"id": "L", "text": "(4) False", "is_correct": true, "explanation": ""}
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_b0b943a902cd448cb313fdadb2cb6887",
        "type": "multiple_choice_multiple_answer",
        "question": "You create a new Azure subscription. No resources are provisioned in the subscription.\n\nYou need to create an Azure Machine Learning workspace.\n\nWhat are three possible ways to achieve this goal? Each correct answer presents a complete solution.\n\nNOTE: Each correct selection is worth one point.",
        "options": [
            {"id": "A", "text": "Use Azure ML Python SDK (v2)\n\n```\nml_client = MLClient.from_config()\nworkspace = ml_client.begin_create(workspace_name)\n```\nwill create resource group automatically", "is_correct": false, "explanation": "Resource group is not created automatically."},
            {"id": "B", "text": "Use Azure Portal", "is_correct": true, "explanation": "In Azure Portal, one can create ML workspace (incl. new resource group if needed)"},
            {"id": "C", "text": "Use Azure ML Studio", "is_correct": true, "explanation": "In Azure ML Studio, one can create ML workspace (incl. new resource group if needed)"},
            {"id": "D", "text": "Use Azure CLI v2 `az group create -n <resource-group> -l <location> && az ml workspace create -n <workspace-name> -g <resource-group>`", "is_correct": true, "explanation": "This will work."},
            {"id": "E", "text": "Use Azure ML Python SDK (v2) after creating resource group\n\n```\nml_client = MLClient.from_config()\nworkspace = ml_client.get(workspace_name)\n```", "is_correct": false, "explanation": "`.get` does not create."},
            {"id": "F", "text": "Use Azure ML Python SDK (v2) after creating resource group\n\n```\nml_client = MLClient.from_config()\nworkspace = ml_client.begin_create(workspace_name)\n```", "is_correct": true, "explanation": "Correct if resource group exists."}
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_88ef956645bf49df953f08f089e8ffab",
        "type": "ordering",
        "question": "You are using a Git repository to track work in an Azure Machine Learning workspace.\n\nYou need to authenticate a Git account by using SSH.\n\nWhich three actions should you perform in sequence?",
        "options": [
            {
                "id": "A",
                "text": "Generate a public/private key pair",
                "explanation": "`ssh-keygen -t ed25519` you@example.com"
            },
            {
                "id": "B",
                "text": "Add the private key to the Git account",
                "explanation": "yeah.. maybe don't."
            },
            {
                "id": "C",
                "text": "Clone the Git repository by using a SSH repository URL",
                "explanation": "`git clone git@github.com:your-username/your-repo.git`"
            },
            {
                "id": "D",
                "text": "Add the public key to the Git account",
                "explanation": "yes"
            },
            {
                "id": "E",
                "text": "Create a new Azue Key Vault resources"
            }
        ],
        "correct_order": [
            "A",
            "D",
            "C"
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_01a083e685344e038d9298339b77d790",
        "type": "multiple_choice_single_answer",
        "question": "You train classification models by using automated machine learning.\n\nYou must evaluate automated machine learning experiment results. You must use charts generated by automated machine learning.\n\nYou need to choose a chart type for each model type.\n\nWhich chart types should you use?",
        "options": [
            {"id": "A", "text": "Confusion Matrix", "is_correct": true},
            {"id": "B", "text": "Predicted vs. True", "is_correct": false},
            {"id": "C", "text": "Calibration curve", "is_correct": false}
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_01a083e685344e038d9298339b77d791",
        "type": "multiple_choice_single_answer",
        "question": "You train regression models by using automated machine learning.\n\nYou must evaluate automated machine learning experiment results. You must use charts generated by automated machine learning.\n\nYou need to choose a chart type for each model type.\n\nWhich chart types should you use?",
        "options": [
            {"id": "A", "text": "Confusion Matrix", "is_correct": false},
            {"id": "B", "text": "Predicted vs. True", "is_correct": true},
            {"id": "C", "text": "Calibration curve", "is_correct": false}
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_1547e562708f46888215bf97233dac65",
        "type": "multiple_choice_multiple_answer",
        "question": "You create an Azure Data Lake Storage Gen2 storage account named storage1containing a file system named fs1 and a folder named folder1.\n\nThe contents of folder1 must be accessible from jobs on compute targets in the Azure Machine Learning workspace.\n\nYou need to construct a URI to reference folder1.\n\nHow should you construct the URI `<1>://<2>`?",
        "options": [
            {"id": "A", "text": "(1) https", "is_correct": false},
            {"id": "B", "text": "(1) abfss", "is_correct": true},
            {"id": "C", "text": "(1) azureml", "is_correct": false},
            {"id": "D", "text": "(2) fs1@storage1.dfs.core.windows.net/folder1/", "is_correct": true},
            {"id": "E", "text": "(2) storage1.blobl.core.windows.net/fs1/folder1/", "is_correct": false},
            {"id": "F", "text": "(2) datastores/storages1/paths/fs1/folder1/", "is_correct": false}
        ],
        "feedback": "",
        "include_in_bank": true
    },
    {
        "question_id": "examtopics_e3081345094d46f8be1903596a73a7c3",
        "type": "multiple_choice_multiple_answer",
        "question": "You train a model by using Azure Machine Learning. You use Azure Blob Storage to store production data.\n\nThe model must be re-trained when new data is uploaded to Azure Blob Storage. You need to minimize development and coding.\n\nYou need to configure Azure services to develop a re-training solution.\n\nWhich Azure services should you use to:\n\n1. Identify when new data is uploaded.\n\n2. Trigger re-training",
        "options": [
            {"id": "A", "text": "(1) Event Grid", "is_correct": true},
            {"id": "B", "text": "(1) Event Hubs", "is_correct": false},
            {"id": "C", "text": "(1) Functions", "is_correct": false},
            {"id": "D", "text": "(2) Event Grid", "is_correct": false},
            {"id": "E", "text": "(2) Functions", "is_correct": false},
            {"id": "F", "text": "(2) Logic Apps", "is_correct": true}
        ],
        "feedback": "Answers say Function -> Event Grid\n\nCommunity says Event Grid -> Logic Apps.",
        "include_in_bank": true
    }
]